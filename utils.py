# utils.py
# PDF ì—…ë¡œë“œ â†’ í…ìŠ¤íŠ¸ ì¶”ì¶œ
from PyPDF2 import PdfReader
import os
import glob

def get_pdf_list(folder_path="pdfs"):
    """ì§€ì •ëœ í´ë”ì—ì„œ PDF íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        # pdfs í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(folder_path):
            os.makedirs(folder_path)
            return []
        
        # í´ë” ë‚´ ëª¨ë“  íŒŒì¼ í™•ì¸
        all_files = os.listdir(folder_path)
        
        # PDF íŒŒì¼ë§Œ í•„í„°ë§ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
        pdf_files = []
        for file in all_files:
            if file.lower().endswith('.pdf'):
                pdf_files.append(file)
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        pdf_files = list(set(pdf_files))  # ì¤‘ë³µ ì œê±°
        return sorted(pdf_files)
    except Exception as e:
        print(f"PDF ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
        return []

def pdf_to_text(file_path_or_uploaded):
    """íŒŒì¼ ê²½ë¡œ ë˜ëŠ” ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        if isinstance(file_path_or_uploaded, str):
            # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
            if not os.path.exists(file_path_or_uploaded):
                return f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path_or_uploaded}"
            
            with open(file_path_or_uploaded, 'rb') as file:
                pdf = PdfReader(file)
                text = ""
                for page in pdf.pages:
                    text += page.extract_text()
        else:
            # ì—…ë¡œë“œëœ íŒŒì¼ì¸ ê²½ìš°
            pdf = PdfReader(file_path_or_uploaded)
            text = ""
            for page in pdf.pages:
                text += page.extract_text()
        
        if not text.strip():
            return "PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ê¸°ë°˜ PDFì´ê±°ë‚˜ ë³´í˜¸ëœ íŒŒì¼ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        
        return text
    except Exception as e:
        return f"PDF ì½ê¸° ì˜¤ë¥˜: {str(e)}"

# í…ìŠ¤íŠ¸ â†’ ë¬¸ë‹¨ ë‚˜ëˆ„ê³  ì„ë² ë”©
try:
    from langchain.text_splitter import CharacterTextSplitter
    try:
        from langchain_community.embeddings import HuggingFaceEmbeddings
        from langchain_community.vectorstores import FAISS
    except ImportError:
        from langchain.embeddings import HuggingFaceEmbeddings
        from langchain.vectorstores import FAISS
    from langchain.chains import RetrievalQA
    from langchain.prompts import PromptTemplate
    LANGCHAIN_AVAILABLE = True
except ImportError as e:
    print(f"LangChain import ì˜¤ë¥˜: {e}")
    LANGCHAIN_AVAILABLE = False
    
import os

def create_vectorstore(text):
    if not LANGCHAIN_AVAILABLE:
        print("LangChainì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    try:
        if not text or len(text.strip()) < 50:
            print("í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
            return None
            
        splitter = CharacterTextSplitter(separator="\n", chunk_size=1000, chunk_overlap=200)
        chunks = splitter.split_text(text)
        
        if not chunks:
            print("í…ìŠ¤íŠ¸ ë¶„í• ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return None

        # HuggingFace ë¬´ë£Œ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (OpenAI API í‚¤ ë¬¸ì œ í•´ê²°)
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2",
            model_kwargs={'device': 'cpu'}
        )
        vectorstore = FAISS.from_texts(chunks, embeddings)

        return vectorstore
    except Exception as e:
        print(f"ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

# ğŸš€ ìˆ˜ìµí™” ê¸°ëŠ¥ë“¤

# 1. ì‚¬ìš©ì ë§ì¶¤ í•™ìŠµ ì´ë ¥ ê´€ë¦¬
import datetime
import json
import hashlib
import uuid
import openai

def create_personalized_learning_path(username, learning_history, preferences=None):
    """ì‚¬ìš©ì ë§ì¶¤ í•™ìŠµ ê²½ë¡œ ìƒì„±"""
    try:
        client = openai.OpenAI()
        
        # í•™ìŠµ ì´ë ¥ ë¶„ì„
        recent_topics = []
        weak_areas = []
        strong_areas = []
        
        for record in learning_history[-10:]:  # ìµœê·¼ 10ê°œ ê¸°ë¡
            question = record.get('question', '')
            answer = record.get('answer', '')
            
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë¶„ì„
            if 'ì–´ë ¤ì›Œ' in question or 'ëª¨ë¥´ê² ' in question:
                weak_areas.append(question[:50])
            elif 'ì˜ ì•Œê² ' in answer or 'ì´í•´í–ˆ' in answer:
                strong_areas.append(question[:50])
        
        prompt = f"""
        ì‚¬ìš©ì {username}ì˜ í•™ìŠµ ì´ë ¥ì„ ë¶„ì„í•˜ì—¬ ë§ì¶¤ í•™ìŠµ ê²½ë¡œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.
        
        ìµœê·¼ í•™ìŠµ ì£¼ì œ: {recent_topics}
        ì•½í•œ ì˜ì—­: {weak_areas}
        ê°•í•œ ì˜ì—­: {strong_areas}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œì•ˆí•´ì£¼ì„¸ìš”:
        1. í˜„ì¬ í•™ìŠµ ìˆ˜ì¤€ í‰ê°€
        2. ì¶”ì²œ í•™ìŠµ ìˆœì„œ (3ë‹¨ê³„)
        3. ê° ë‹¨ê³„ë³„ ì˜ˆìƒ ì†Œìš” ì‹œê°„
        4. ë§ì¶¤ í•™ìŠµ ì „ëµ
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=800,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ë§ì¶¤ í•™ìŠµ ê²½ë¡œ ìƒì„± ì‹¤íŒ¨: {str(e)}"

def generate_adaptive_quiz(username, learning_history, difficulty_level="medium"):
    """ì‚¬ìš©ì ìˆ˜ì¤€ì— ë§ëŠ” ì ì‘í˜• í€´ì¦ˆ ìƒì„±"""
    try:
        client = openai.OpenAI()
        
        # ì‚¬ìš©ì ì•½ì  ë¶„ì„
        weak_topics = analyze_weak_areas(learning_history)
        
        prompt = f"""
        ì‚¬ìš©ì {username}ì˜ ì•½ì ì„ ë³´ì™„í•˜ëŠ” ì ì‘í˜• í€´ì¦ˆë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        
        ì•½ì  ì˜ì—­: {weak_topics}
        ë‚œì´ë„: {difficulty_level}
        
        5ê°œì˜ ë¬¸ì œë¥¼ ìƒì„±í•˜ë˜, ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•´ì£¼ì„¸ìš”:
        1. ì•½ì  ì˜ì—­ ì§‘ì¤‘ (70%)
        2. ë³µìŠµ ë¬¸ì œ (30%)
        3. ë‹¨ê³„ë³„ ë‚œì´ë„ ì¦ê°€
        4. ìƒì„¸í•œ í•´ì„¤ í¬í•¨
        
        í˜•ì‹:
        Q1: [ë¬¸ì œ]
        1) ì„ íƒì§€1 2) ì„ íƒì§€2 3) ì„ íƒì§€3 4) ì„ íƒì§€4
        ì •ë‹µ: [ë²ˆí˜¸]
        í•´ì„¤: [ìƒì„¸ ì„¤ëª…]
        í•™ìŠµ íŒ: [ì¶”ê°€ í•™ìŠµ ë°©í–¥]
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2000,
            temperature=0.4
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ì ì‘í˜• í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {str(e)}"

def analyze_weak_areas(learning_history):
    """í•™ìŠµ ì´ë ¥ì—ì„œ ì•½ì  ì˜ì—­ ë¶„ì„"""
    weak_areas = []
    for record in learning_history:
        question = record.get('question', '').lower()
        if any(word in question for word in ['ì–´ë ¤ì›Œ', 'ëª¨ë¥´ê² ', 'ì´í•´ ì•ˆ', 'í—·ê°ˆë ¤']):
            # í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = question.split()[:3]  # ì•ì˜ 3ë‹¨ì–´
            weak_areas.extend(keywords)
    
    # ë¹ˆë„ìˆ˜ ê¸°ë°˜ ì•½ì  ì˜ì—­ ë°˜í™˜
    from collections import Counter
    common_weak = Counter(weak_areas).most_common(5)
    return [item[0] for item in common_weak]

# 2. ê°•ì‚¬ìš© ì„œë¹„ìŠ¤ - PDF â†’ ì±—ë´‡ â†’ ê³µìœ  ë§í¬
def create_instructor_chatbot(instructor_name, pdf_content, course_name):
    """ê°•ì‚¬ìš© ì±—ë´‡ ìƒì„±"""
    try:
        # ê³ ìœ  ì±—ë´‡ ID ìƒì„±
        chatbot_id = str(uuid.uuid4())[:8]
        
        # ì±—ë´‡ ë°ì´í„° ì €ì¥
        os.makedirs("instructor_bots", exist_ok=True)
        bot_data = {
            "chatbot_id": chatbot_id,
            "instructor_name": instructor_name,
            "course_name": course_name,
            "pdf_content": pdf_content[:5000],  # ë¯¸ë¦¬ë³´ê¸°ìš©
            "created_at": datetime.datetime.now().isoformat(),
            "access_count": 0,
            "student_interactions": [],
            "share_link": f"https://your-domain.com/chatbot/{chatbot_id}",
            "is_active": True
        }
        
        with open(f"instructor_bots/{chatbot_id}.json", 'w', encoding='utf-8') as f:
            json.dump(bot_data, f, ensure_ascii=False, indent=2)
        
        return chatbot_id, bot_data["share_link"]
    except Exception as e:
        return None, f"ì±—ë´‡ ìƒì„± ì‹¤íŒ¨: {str(e)}"

def generate_shareable_quiz_link(quiz_content, instructor_name, course_name):
    """ê³µìœ  ê°€ëŠ¥í•œ í€´ì¦ˆ ë§í¬ ìƒì„±"""
    try:
        quiz_id = str(uuid.uuid4())[:8]
        
        os.makedirs("shared_quizzes", exist_ok=True)
        quiz_data = {
            "quiz_id": quiz_id,
            "instructor_name": instructor_name,
            "course_name": course_name,
            "quiz_content": quiz_content,
            "created_at": datetime.datetime.now().isoformat(),
            "access_count": 0,
            "student_results": [],
            "share_link": f"https://your-domain.com/quiz/{quiz_id}",
            "is_active": True,
            "time_limit": 30  # ë¶„
        }
        
        with open(f"shared_quizzes/{quiz_id}.json", 'w', encoding='utf-8') as f:
            json.dump(quiz_data, f, ensure_ascii=False, indent=2)
        
        return quiz_id, quiz_data["share_link"]
    except Exception as e:
        return None, f"í€´ì¦ˆ ë§í¬ ìƒì„± ì‹¤íŒ¨: {str(e)}"

# 3. ì˜ˆìƒë¬¸ì œ ìƒì„± (ìœ ë£Œ ê¸°ëŠ¥)
def generate_premium_exam_questions(pdf_content, exam_type="midterm", num_questions=20):
    """í”„ë¦¬ë¯¸ì—„ ì˜ˆìƒë¬¸ì œ ìƒì„±"""
    try:
        client = openai.OpenAI()
        
        prompt = f"""
        ë‹¤ìŒ êµì¬ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ {exam_type} ì‹œí—˜ ì˜ˆìƒë¬¸ì œ {num_questions}ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        
        êµì¬ ë‚´ìš©:
        {pdf_content[:4000]}
        
        ìš”êµ¬ì‚¬í•­:
        1. ì‹¤ì œ ì‹œí—˜ê³¼ ìœ ì‚¬í•œ ë‚œì´ë„
        2. ë‹¤ì–‘í•œ ë¬¸ì œ ìœ í˜• (ê°ê´€ì‹, ë‹¨ë‹µí˜•, ì„œìˆ í˜•)
        3. ì¶œì œ ë¹ˆë„ê°€ ë†’ì€ í•µì‹¬ ê°œë… ìœ„ì£¼
        4. ìƒì„¸í•œ í•´ì„¤ê³¼ ì±„ì  ê¸°ì¤€
        5. ì˜ˆìƒ ì¶œì œ í™•ë¥  í‘œì‹œ
        
        í˜•ì‹:
        [ë¬¸ì œ ë²ˆí˜¸] (ì¶œì œí™•ë¥ : â˜…â˜…â˜…â˜†â˜†)
        ë¬¸ì œ: [ë‚´ìš©]
        ì •ë‹µ: [ë‹µì•ˆ]
        í•´ì„¤: [ìƒì„¸ ì„¤ëª…]
        ì±„ì  ê¸°ì¤€: [ë¶€ë¶„ì ìˆ˜ ê¸°ì¤€]
        ê´€ë ¨ ê°œë…: [ì—°ê´€ í•™ìŠµ ë‚´ìš©]
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=3000,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ì˜ˆìƒë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {str(e)}"

def create_premium_study_package(username, pdf_content, package_type="complete"):
    """í”„ë¦¬ë¯¸ì—„ í•™ìŠµ íŒ¨í‚¤ì§€ ìƒì„±"""
    try:
        package_id = str(uuid.uuid4())[:8]
        
        # íŒ¨í‚¤ì§€ êµ¬ì„± ìš”ì†Œ ìƒì„±
        components = {}
        
        if package_type in ["complete", "quiz"]:
            components["adaptive_quiz"] = generate_adaptive_quiz(username, [], "advanced")
            components["exam_questions"] = generate_premium_exam_questions(pdf_content)
        
        if package_type in ["complete", "summary"]:
            components["detailed_summary"] = generate_detailed_summary(pdf_content)
            components["concept_map"] = generate_concept_map(pdf_content)
        
        if package_type in ["complete", "practice"]:
            components["practice_problems"] = generate_practice_problems(pdf_content)
            components["solution_guide"] = generate_solution_guide(pdf_content)
        
        # íŒ¨í‚¤ì§€ ì €ì¥
        os.makedirs("premium_packages", exist_ok=True)
        package_data = {
            "package_id": package_id,
            "username": username,
            "package_type": package_type,
            "components": components,
            "created_at": datetime.datetime.now().isoformat(),
            "expires_at": (datetime.datetime.now() + datetime.timedelta(days=30)).isoformat(),
            "download_count": 0,
            "price": get_package_price(package_type)
        }
        
        with open(f"premium_packages/{package_id}.json", 'w', encoding='utf-8') as f:
            json.dump(package_data, f, ensure_ascii=False, indent=2)
        
        return package_id, package_data
    except Exception as e:
        return None, f"í”„ë¦¬ë¯¸ì—„ íŒ¨í‚¤ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}"

def get_package_price(package_type):
    """íŒ¨í‚¤ì§€ íƒ€ì…ë³„ ê°€ê²© ë°˜í™˜"""
    prices = {
        "quiz": 5000,      # 5,000ì›
        "summary": 3000,   # 3,000ì›
        "practice": 7000,  # 7,000ì›
        "complete": 12000  # 12,000ì› (í• ì¸ê°€)
    }
    return prices.get(package_type, 5000)

# 4. í•™ì› ì œíœ´ ê¸°ëŠ¥
def create_academy_dashboard(academy_name, instructor_list):
    """í•™ì›ìš© ëŒ€ì‹œë³´ë“œ ìƒì„±"""
    try:
        academy_id = str(uuid.uuid4())[:8]
        
        os.makedirs("academy_accounts", exist_ok=True)
        academy_data = {
            "academy_id": academy_id,
            "academy_name": academy_name,
            "instructors": instructor_list,
            "created_at": datetime.datetime.now().isoformat(),
            "subscription_plan": "basic",  # basic, premium, enterprise
            "monthly_usage": {
                "chatbots_created": 0,
                "students_served": 0,
                "quizzes_generated": 0,
                "api_calls": 0
            },
            "features": {
                "max_instructors": 5,
                "max_chatbots": 20,
                "max_students_per_bot": 100,
                "analytics": True,
                "white_label": False
            }
        }
        
        with open(f"academy_accounts/{academy_id}.json", 'w', encoding='utf-8') as f:
            json.dump(academy_data, f, ensure_ascii=False, indent=2)
        
        return academy_id, academy_data
    except Exception as e:
        return None, f"í•™ì› ê³„ì • ìƒì„± ì‹¤íŒ¨: {str(e)}"

def generate_academy_analytics(academy_id):
    """í•™ì›ìš© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
    try:
        # í•™ì› ë°ì´í„° ë¡œë“œ
        with open(f"academy_accounts/{academy_id}.json", 'r', encoding='utf-8') as f:
            academy_data = json.load(f)
        
        # ë¶„ì„ ë°ì´í„° ìˆ˜ì§‘
        analytics = {
            "period": "last_30_days",
            "total_students": academy_data["monthly_usage"]["students_served"],
            "active_chatbots": academy_data["monthly_usage"]["chatbots_created"],
            "quiz_completion_rate": 85.2,  # ì˜ˆì‹œ ë°ì´í„°
            "student_satisfaction": 4.3,   # 5ì  ë§Œì 
            "most_popular_subjects": ["ìˆ˜í•™", "ì˜ì–´", "ê³¼í•™"],
            "peak_usage_hours": ["19:00-21:00", "14:00-16:00"],
            "revenue_generated": academy_data["monthly_usage"]["students_served"] * 1000
        }
        
        return analytics
    except Exception as e:
        return f"ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}"

# 5. ë¶€ê°€ ê¸°ëŠ¥ë“¤
def generate_detailed_summary(pdf_content):
    """ìƒì„¸ ìš”ì•½ ìƒì„±"""
    try:
        client = openai.OpenAI()
        
        prompt = f"""
        ë‹¤ìŒ ë‚´ìš©ì„ ì²´ê³„ì ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:
        
        {pdf_content[:3000]}
        
        ë‹¤ìŒ êµ¬ì¡°ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:
        1. í•µì‹¬ ê°œë… (5ê°œ)
        2. ì£¼ìš” ë‚´ìš© ì •ë¦¬
        3. ì¤‘ìš” ê³µì‹/ë²•ì¹™
        4. ì‹¤ì œ ì ìš© ì‚¬ë¡€
        5. ì—°ê´€ í•™ìŠµ ì£¼ì œ
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1500,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ìƒì„¸ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}"

def generate_concept_map(pdf_content):
    """ê°œë… ë§µ ìƒì„±"""
    try:
        client = openai.OpenAI()
        
        prompt = f"""
        ë‹¤ìŒ ë‚´ìš©ì˜ ê°œë… ë§µì„ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ìƒì„±í•´ì£¼ì„¸ìš”:
        
        {pdf_content[:2000]}
        
        í˜•ì‹:
        ì¤‘ì‹¬ ê°œë…: [ë©”ì¸ ì£¼ì œ]
        â”œâ”€â”€ í•˜ìœ„ ê°œë… 1
        â”‚   â”œâ”€â”€ ì„¸ë¶€ ë‚´ìš© 1-1
        â”‚   â””â”€â”€ ì„¸ë¶€ ë‚´ìš© 1-2
        â”œâ”€â”€ í•˜ìœ„ ê°œë… 2
        â”‚   â”œâ”€â”€ ì„¸ë¶€ ë‚´ìš© 2-1
        â”‚   â””â”€â”€ ì„¸ë¶€ ë‚´ìš© 2-2
        â””â”€â”€ í•˜ìœ„ ê°œë… 3
            â”œâ”€â”€ ì„¸ë¶€ ë‚´ìš© 3-1
            â””â”€â”€ ì„¸ë¶€ ë‚´ìš© 3-2
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1000,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ê°œë… ë§µ ìƒì„± ì‹¤íŒ¨: {str(e)}"

def generate_practice_problems(pdf_content):
    """ì—°ìŠµ ë¬¸ì œ ìƒì„±"""
    try:
        client = openai.OpenAI()
        
        prompt = f"""
        ë‹¤ìŒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì—°ìŠµ ë¬¸ì œ 10ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”:
        
        {pdf_content[:3000]}
        
        ë¬¸ì œ ìœ í˜•:
        - ê¸°ì´ˆ ë¬¸ì œ (3ê°œ)
        - ì‘ìš© ë¬¸ì œ (4ê°œ)  
        - ì‹¬í™” ë¬¸ì œ (3ê°œ)
        
        ê° ë¬¸ì œë§ˆë‹¤ ë‚œì´ë„ì™€ ì˜ˆìƒ ì†Œìš” ì‹œê°„ì„ í‘œì‹œí•´ì£¼ì„¸ìš”.
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2000,
            temperature=0.4
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ì—°ìŠµ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {str(e)}"

def generate_solution_guide(pdf_content):
    """í•´ì„¤ ê°€ì´ë“œ ìƒì„±"""
    try:
        client = openai.OpenAI()
        
        prompt = f"""
        ë‹¤ìŒ ë‚´ìš©ì— ëŒ€í•œ ë¬¸ì œ í•´ê²° ê°€ì´ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
        
        {pdf_content[:2000]}
        
        í¬í•¨ ë‚´ìš©:
        1. ë¬¸ì œ ì ‘ê·¼ ë°©ë²•
        2. ë‹¨ê³„ë³„ í•´ê²° ê³¼ì •
        3. ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜
        4. í™•ì¸ ë°©ë²•
        5. ìœ ì‚¬ ë¬¸ì œ í•´ê²° íŒ
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1500,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"í•´ì„¤ ê°€ì´ë“œ ìƒì„± ì‹¤íŒ¨: {str(e)}"

# ëˆ„ë½ëœ í•¨ìˆ˜ë“¤ ì¶”ê°€
def create_qa_chain(vectorstore):
    """QA ì²´ì¸ ìƒì„±"""
    if not LANGCHAIN_AVAILABLE:
        print("LangChainì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    if vectorstore is None:
        print("ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    try:
        # API í‚¤ í™•ì¸
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
            
        retriever = vectorstore.as_retriever()
        
        # ìµœì‹  ëª¨ë¸ ì‚¬ìš©
        try:
            from langchain_openai import ChatOpenAI
        except ImportError:
            from langchain.chat_models import ChatOpenAI
        
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, api_key=api_key)
        from langchain.chains import RetrievalQA
        chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)
        return chain
    except Exception as e:
        print(f"QA ì²´ì¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def authenticate_user(username, password):
    """ì‚¬ìš©ì ì¸ì¦"""
    try:
        users_file = "users/users.json"
        with open(users_file, 'r', encoding='utf-8') as f:
            users = json.load(f)
        
        if username in users:
            stored_password = users[username]["password"]
            if stored_password == hash_password(password):
                # ë¡œê·¸ì¸ ì‹œê°„ ì—…ë°ì´íŠ¸
                users[username]["last_login"] = datetime.datetime.now().isoformat()
                
                with open(users_file, 'w', encoding='utf-8') as f:
                    json.dump(users, f, ensure_ascii=False, indent=2)
                
                return users[username]
        
        return None
    except FileNotFoundError:
        return None
    except Exception as e:
        print(f"ì¸ì¦ ì˜¤ë¥˜: {e}")
        return None

def hash_password(password):
    """ë¹„ë°€ë²ˆí˜¸ í•´ì‹œí™”"""
    return hashlib.sha256(password.encode()).hexdigest()

def create_user(username, password, plan="free"):
    """ìƒˆ ì‚¬ìš©ì ìƒì„±"""
    try:
        os.makedirs("users", exist_ok=True)
        users_file = "users/users.json"
        
        # ê¸°ì¡´ ì‚¬ìš©ì ëª©ë¡ ë¡œë“œ
        try:
            with open(users_file, 'r', encoding='utf-8') as f:
                users = json.load(f)
        except FileNotFoundError:
            users = {}
        
        # ì‚¬ìš©ìëª… ì¤‘ë³µ í™•ì¸
        if username in users:
            return False
        
        # ìƒˆ ì‚¬ìš©ì ì¶”ê°€
        users[username] = {
            "username": username,
            "password": hash_password(password),
            "plan": plan,
            "created_at": datetime.datetime.now().isoformat(),
            "last_login": None,
            "usage_stats": {
                "total_questions": 0,
                "total_pdfs": 0,
                "total_quizzes": 0,
                "api_calls_today": 0,
                "last_api_call": None
            }
        }
        
        # ì €ì¥
        with open(users_file, 'w', encoding='utf-8') as f:
            json.dump(users, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        print(f"ì‚¬ìš©ì ìƒì„± ì˜¤ë¥˜: {e}")
        return False

def load_user_documents(username):
    """ì‚¬ìš©ìë³„ ì„ íƒëœ ë¬¸ì„œ ëª©ë¡ ë¡œë“œ"""
    try:
        user_docs_file = f"users/{username}_documents.json"
        with open(user_docs_file, 'r', encoding='utf-8') as f:
            doc_data = json.load(f)
        return doc_data.get("selected_documents", [])
    except FileNotFoundError:
        return []
    except Exception as e:
        print(f"ì‚¬ìš©ì ë¬¸ì„œ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return []

def get_document_summary(pdf_name, text):
    """ë¬¸ì„œë³„ ê°„ë‹¨í•œ ìš”ì•½ ìƒì„±"""
    try:
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
        preview_text = text[:1000] if len(text) > 1000 else text
        
        client = openai.OpenAI()
        prompt = f"""
        ë‹¤ìŒ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ 2-3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:
        
        ë¬¸ì„œëª…: {pdf_name}
        ë‚´ìš©: {preview_text}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=200,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}"

def save_user_documents(username, selected_pdfs):
    """ì‚¬ìš©ìë³„ ì„ íƒëœ ë¬¸ì„œ ëª©ë¡ ì €ì¥"""
    try:
        user_docs_file = f"users/{username}_documents.json"
        os.makedirs("users", exist_ok=True)
        
        doc_data = {
            "username": username,
            "selected_documents": selected_pdfs,
            "last_updated": datetime.datetime.now().isoformat(),
            "document_count": len(selected_pdfs)
        }
        
        with open(user_docs_file, 'w', encoding='utf-8') as f:
            json.dump(doc_data, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        print(f"ì‚¬ìš©ì ë¬¸ì„œ ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

def check_plan_limits(username, feature_type):
    """í”Œëœë³„ ê¸°ëŠ¥ ì œí•œ í™•ì¸"""
    try:
        users_file = "users/users.json"
        with open(users_file, 'r', encoding='utf-8') as f:
            users = json.load(f)
        
        if username not in users:
            return False, "ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        user = users[username]
        plan = user.get("plan", "free")
        usage = user.get("usage_stats", {})
        
        # ë¬´ë£Œ í”Œëœ ì œí•œ
        if plan == "free":
            if feature_type == "pdf_upload":
                if usage.get("total_pdfs", 0) >= 10:  # ì¼ì¼ 10ê°œ ì œí•œ
                    return False, "ë¬´ë£Œ í”Œëœì€ ì¼ì¼ 10ê°œ PDF ì œí•œì…ë‹ˆë‹¤."
            elif feature_type == "quiz_generation":
                if usage.get("total_quizzes", 0) >= 5:  # ì¼ì¼ 5ê°œ ì œí•œ
                    return False, "ë¬´ë£Œ í”Œëœì€ ì¼ì¼ 5ê°œ í€´ì¦ˆ ì œí•œì…ë‹ˆë‹¤."
            elif feature_type == "multi_document":
                return False, "ë‹¤ì¤‘ ë¬¸ì„œ ê¸°ëŠ¥ì€ í”„ë¦¬ë¯¸ì—„ í”Œëœì´ í•„ìš”í•©ë‹ˆë‹¤."
            elif feature_type == "api_calls":
                today = datetime.datetime.now().date().isoformat()
                last_call = usage.get("last_api_call", "")
                if last_call.startswith(today):
                    if usage.get("api_calls_today", 0) >= 50:  # ì¼ì¼ 50íšŒ ì œí•œ
                        return False, "ë¬´ë£Œ í”Œëœì€ ì¼ì¼ 50íšŒ API í˜¸ì¶œ ì œí•œì…ë‹ˆë‹¤."
        
        return True, "ì‚¬ìš© ê°€ëŠ¥"
    except Exception as e:
        print(f"í”Œëœ ì œí•œ í™•ì¸ ì˜¤ë¥˜: {e}")
        return True, "í™•ì¸ ë¶ˆê°€"

def update_user_activity(username, activity_type, data=None):
    """ì‚¬ìš©ì í™œë™ ì—…ë°ì´íŠ¸"""
    try:
        os.makedirs("users", exist_ok=True)
        activity_file = f"users/{username}_activity.json"
        
        # ê¸°ì¡´ í™œë™ ë¡œë“œ
        try:
            with open(activity_file, 'r', encoding='utf-8') as f:
                activity = json.load(f)
        except FileNotFoundError:
            activity = {
                "username": username,
                "total_questions": 0,
                "total_pdfs": 0,
                "total_quizzes": 0,
                "last_activity": None,
                "activities": []
            }
        
        # í™œë™ ì—…ë°ì´íŠ¸
        if activity_type == "question_asked":
            activity["total_questions"] += 1
        elif activity_type == "pdf_processed":
            activity["total_pdfs"] += 1
        elif activity_type == "quiz_completed":
            activity["total_quizzes"] += 1
        
        activity["last_activity"] = datetime.datetime.now().isoformat()
        
        # í™œë™ ê¸°ë¡ ì¶”ê°€
        activity["activities"].append({
            "type": activity_type,
            "timestamp": datetime.datetime.now().isoformat(),
            "data": data
        })
        
        # ìµœê·¼ 50ê°œ í™œë™ë§Œ ìœ ì§€
        if len(activity["activities"]) > 50:
            activity["activities"] = activity["activities"][-50:]
        
        # ì €ì¥
        with open(activity_file, 'w', encoding='utf-8') as f:
            json.dump(activity, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        print(f"ì‚¬ìš©ì í™œë™ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
        return False

# ğŸ†• ë‹¤ì¤‘ ë¬¸ì„œ ì§€ì› ê¸°ëŠ¥
def create_multi_vectorstore(texts_dict):
    """ì—¬ëŸ¬ PDFì˜ í…ìŠ¤íŠ¸ë¡œ í†µí•© ë²¡í„°ìŠ¤í† ì–´ ìƒì„±"""
    try:
        splitter = CharacterTextSplitter(separator="\n", chunk_size=1000, chunk_overlap=200)
        
        all_chunks = []
        metadata_list = []
        
        for pdf_name, text in texts_dict.items():
            chunks = splitter.split_text(text)
            all_chunks.extend(chunks)
            
            # ê° ì²­í¬ì— ì¶œì²˜ ì •ë³´ ì¶”ê°€
            for chunk in chunks:
                metadata_list.append({"source": pdf_name})
        
        # HuggingFace ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2",
            model_kwargs={'device': 'cpu'}
        )
        
        # ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        vectorstore = FAISS.from_texts(all_chunks, embeddings, metadatas=metadata_list)
        
        return vectorstore
    except Exception as e:
        print(f"ë‹¤ì¤‘ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def save_user_documents(username, selected_pdfs):
    """ì‚¬ìš©ìë³„ ì„ íƒëœ ë¬¸ì„œ ëª©ë¡ ì €ì¥"""
    try:
        user_docs_file = f"users/{username}_documents.json"
        os.makedirs("users", exist_ok=True)
        
        doc_data = {
            "username": username,
            "selected_documents": selected_pdfs,
            "last_updated": datetime.datetime.now().isoformat(),
            "document_count": len(selected_pdfs)
        }
        
        with open(user_docs_file, 'w', encoding='utf-8') as f:
            json.dump(doc_data, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        print(f"ì‚¬ìš©ì ë¬¸ì„œ ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

def load_user_documents(username):
    """ì‚¬ìš©ìë³„ ì„ íƒëœ ë¬¸ì„œ ëª©ë¡ ë¡œë“œ"""
    try:
        user_docs_file = f"users/{username}_documents.json"
        with open(user_docs_file, 'r', encoding='utf-8') as f:
            doc_data = json.load(f)
        return doc_data.get("selected_documents", [])
    except FileNotFoundError:
        return []
    except Exception as e:
        print(f"ì‚¬ìš©ì ë¬¸ì„œ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return []

def get_document_summary(pdf_name, text):
    """ë¬¸ì„œë³„ ê°„ë‹¨í•œ ìš”ì•½ ìƒì„±"""
    try:
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
        preview_text = text[:1000] if len(text) > 1000 else text
        
        client = openai.OpenAI()
        prompt = f"""
        ë‹¤ìŒ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ 2-3ì¤„ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:
        
        ë¬¸ì„œëª…: {pdf_name}
        ë‚´ìš©: {preview_text}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=200,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}"

def create_cross_document_qa_chain(vectorstore):
    """ë‹¤ì¤‘ ë¬¸ì„œ ì§ˆì˜ì‘ë‹µ ì²´ì¸ ìƒì„±"""
    try:
        if vectorstore is None:
            print("ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        # API í‚¤ í™•ì¸
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
            
        retriever = vectorstore.as_retriever(search_kwargs={"k": 5})  # ë” ë§ì€ ë¬¸ì„œì—ì„œ ê²€ìƒ‰
        
        # ìµœì‹  ëª¨ë¸ ì‚¬ìš©
        try:
            from langchain_openai import ChatOpenAI
        except ImportError:
            from langchain.chat_models import ChatOpenAI
        
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, api_key=api_key)
        
        # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ë¡œ ì¶œì²˜ ì •ë³´ í¬í•¨
        from langchain.chains import RetrievalQA
        from langchain.prompts import PromptTemplate
        
        template = """
        ë‹¤ìŒ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”. 
        ë‹µë³€ ì‹œ ì–´ë–¤ ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì™”ëŠ”ì§€ ì¶œì²˜ë¥¼ ëª…ì‹œí•´ì£¼ì„¸ìš”.
        
        ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©:
        {context}
        
        ì§ˆë¬¸: {question}
        
        ë‹µë³€ (ì¶œì²˜ í¬í•¨):
        """
        
        prompt = PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )
        
        chain = RetrievalQA.from_chain_type(
            llm=llm, 
            retriever=retriever,
            chain_type_kwargs={"prompt": prompt}
        )
        
        return chain
    except Exception as e:
        print(f"ë‹¤ì¤‘ ë¬¸ì„œ QA ì²´ì¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

# ì§ˆì˜ì‘ë‹µ ì²´ì¸ êµ¬ì„± (RAG)
from langchain.chains import RetrievalQA
try:
    from langchain_openai import ChatOpenAI
except ImportError:
    from langchain.chat_models import ChatOpenAI
import openai
import json
import random

def create_qa_chain(vectorstore):
    if not LANGCHAIN_AVAILABLE:
        print("LangChainì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    if vectorstore is None:
        print("ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    try:
        # API í‚¤ í™•ì¸
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
            
        retriever = vectorstore.as_retriever()
        
        # ìµœì‹  ëª¨ë¸ ì‚¬ìš©
        try:
            from langchain_openai import ChatOpenAI
        except ImportError:
            from langchain.chat_models import ChatOpenAI
        
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, api_key=api_key)
        chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)
        return chain
    except Exception as e:
        print(f"QA ì²´ì¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

# í…ìŠ¤íŠ¸ ìš”ì•½ ê¸°ëŠ¥
def summarize_text(text, max_length=500):
    try:
        client = openai.OpenAI()
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ {max_length}ì ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”. 
        ì£¼ìš” ê°œë…ê³¼ í•µì‹¬ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ í•™ìŠµì— ë„ì›€ì´ ë˜ë„ë¡ ìš”ì•½í•´ì£¼ì„¸ìš”.
        
        í…ìŠ¤íŠ¸:
        {text[:3000]}  # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ëŠ” ì˜ë¼ì„œ ì²˜ë¦¬
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=800,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# í€´ì¦ˆ ìƒì„± ê¸°ëŠ¥
def generate_quiz(text, num_questions=5):
    try:
        client = openai.OpenAI()
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ {num_questions}ê°œì˜ ê°ê´€ì‹ í€´ì¦ˆë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        ê° ë¬¸ì œëŠ” 4ê°œì˜ ì„ íƒì§€ë¥¼ ê°€ì§€ê³ , ì •ë‹µì€ 1ê°œì…ë‹ˆë‹¤.
        
        í˜•ì‹:
        Q1: [ì§ˆë¬¸]
        1) [ì„ íƒì§€1]
        2) [ì„ íƒì§€2] 
        3) [ì„ íƒì§€3]
        4) [ì„ íƒì§€4]
        ì •ë‹µ: [ë²ˆí˜¸]
        í•´ì„¤: [ê°„ë‹¨í•œ ì„¤ëª…]
        
        í…ìŠ¤íŠ¸:
        {text[:2000]}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1500,
            temperature=0.5
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"í€´ì¦ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# í•™ìŠµ ì´ë ¥ ê´€ë¦¬
import datetime
import json
import hashlib

def save_study_history(question, answer, filename="study_history.json"):
    try:
        # ê¸°ì¡´ ì´ë ¥ ë¡œë“œ
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                history = json.load(f)
        except FileNotFoundError:
            history = []
        
        # ìƒˆ ê¸°ë¡ ì¶”ê°€
        new_record = {
            "timestamp": datetime.datetime.now().isoformat(),
            "question": question,
            "answer": answer[:200] + "..." if len(answer) > 200 else answer
        }
        
        history.append(new_record)
        
        # ìµœê·¼ 50ê°œë§Œ ìœ ì§€
        if len(history) > 50:
            history = history[-50:]
        
        # ì €ì¥
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
            
        return True
    except Exception as e:
        print(f"ì´ë ¥ ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

def load_study_history(filename="study_history.json"):
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return []
    except Exception as e:
        print(f"ì´ë ¥ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return []

# ğŸ†• ë‹¨ë‹µí˜• í€´ì¦ˆ ìƒì„± ê¸°ëŠ¥
def generate_short_answer_quiz(text, num_questions=5):
    try:
        client = openai.OpenAI()
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ {num_questions}ê°œì˜ ë‹¨ë‹µí˜• í€´ì¦ˆë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        ê° ë¬¸ì œëŠ” ê°„ë‹¨í•œ ë‹¨ì–´ë‚˜ êµ¬ë¬¸ìœ¼ë¡œ ë‹µí•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
        
        í˜•ì‹:
        Q1: [ì§ˆë¬¸]
        ì •ë‹µ: [ë‹¨ë‹µ]
        í•´ì„¤: [ê°„ë‹¨í•œ ì„¤ëª…]
        
        í…ìŠ¤íŠ¸:
        {text[:2000]}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1200,
            temperature=0.5
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ë‹¨ë‹µí˜• í€´ì¦ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ğŸ†• ì±•í„°ë³„ ë¶„ì„ ë° ìš”ì•½
def analyze_chapters(text):
    try:
        client = openai.OpenAI()
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì±•í„°ë‚˜ ì£¼ì œë³„ë¡œ ë‚˜ëˆ„ê³ , ê° ë¶€ë¶„ì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.
        
        í˜•ì‹:
        ## ì±•í„° 1: [ì œëª©]
        - í•µì‹¬ ë‚´ìš©: [ìš”ì•½]
        - ì¤‘ìš” í‚¤ì›Œë“œ: [í‚¤ì›Œë“œë“¤]
        - í•™ìŠµ í¬ì¸íŠ¸: [í•™ìŠµí•´ì•¼ í•  ì ]
        
        í…ìŠ¤íŠ¸:
        {text[:4000]}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2000,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ì±•í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ğŸ†• í•™ìŠµ ë…¸íŠ¸ ìë™ ìƒì„±
def generate_study_notes(text, style="bullet"):
    try:
        client = openai.OpenAI()
        
        if style == "bullet":
            format_instruction = "ë¶ˆë¦¿ í¬ì¸íŠ¸ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬"
        elif style == "outline":
            format_instruction = "ì•„ì›ƒë¼ì¸ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬"
        else:
            format_instruction = "ë§ˆì¸ë“œë§µ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬"
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•™ìŠµ ë…¸íŠ¸ë¡œ {format_instruction}í•´ì£¼ì„¸ìš”.
        í•™ìƒì´ ë³µìŠµí•˜ê¸° ì‰½ë„ë¡ í•µì‹¬ ê°œë…, ì •ì˜, ì˜ˆì‹œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.
        
        í…ìŠ¤íŠ¸:
        {text[:3000]}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1500,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"í•™ìŠµ ë…¸íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ğŸ†• í•™ìŠµ ì§„í–‰ë¥  ê³„ì‚°
def calculate_progress(history, total_chapters=10):
    if not history:
        return 0, {}
    
    # ì§ˆë¬¸ í‚¤ì›Œë“œ ë¶„ì„ìœ¼ë¡œ í•™ìŠµ ì˜ì—­ íŒŒì•…
    topics = {}
    for record in history:
        question = record['question'].lower()
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì£¼ì œ ë¶„ë¥˜
        if any(word in question for word in ['1ì¥', 'ì²«ë²ˆì§¸', 'ì²˜ìŒ', 'chapter 1']):
            topics['Chapter 1'] = topics.get('Chapter 1', 0) + 1
        elif any(word in question for word in ['2ì¥', 'ë‘ë²ˆì§¸', 'chapter 2']):
            topics['Chapter 2'] = topics.get('Chapter 2', 0) + 1
        # ... ë” ë§ì€ ì±•í„° ë§¤ì¹­ ë¡œì§
    
    progress_percentage = min(len(topics) / total_chapters * 100, 100)
    return progress_percentage, topics

# ğŸ†• TTS ê¸°ëŠ¥ (gTTS ì‚¬ìš©)
def text_to_speech(text, lang='ko'):
    try:
        from gtts import gTTS
        import io
        
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½
        if len(text) > 1000:
            text = text[:1000] + "..."
        
        tts = gTTS(text=text, lang=lang, slow=False)
        
        # ë©”ëª¨ë¦¬ì— ì €ì¥
        audio_buffer = io.BytesIO()
        tts.write_to_fp(audio_buffer)
        audio_buffer.seek(0)
        
        return audio_buffer.getvalue()
    except Exception as e:
        return None

# ğŸ†• ì½”ë„¬ ë…¸íŠ¸ í•„ê¸°ë²• ìƒì„±
def generate_cornell_notes(text):
    try:
        client = openai.OpenAI()
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ì½”ë„¬ ë…¸íŠ¸ í•„ê¸°ë²• í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
        ì½”ë„¬ ë…¸íŠ¸ëŠ” 3ê°œ ì˜ì—­ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:
        
        1. ë…¸íŠ¸ ì˜ì—­ (Note-taking Area): ì£¼ìš” ë‚´ìš©ê³¼ ì„¸ë¶€ì‚¬í•­
        2. ë‹¨ì„œ ì˜ì—­ (Cue Column): í•µì‹¬ í‚¤ì›Œë“œ, ì§ˆë¬¸, ì¤‘ìš” í¬ì¸íŠ¸
        3. ìš”ì•½ ì˜ì—­ (Summary): ì „ì²´ ë‚´ìš©ì˜ í•µì‹¬ ìš”ì•½
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
        
        # ğŸ“ ì½”ë„¬ ë…¸íŠ¸
        
        ## ğŸ“‹ ë…¸íŠ¸ ì˜ì—­ (Note-taking Area)
        ### ì£¼ì œ 1: [ì œëª©]
        - [ìƒì„¸ ë‚´ìš©]
        - [ì˜ˆì‹œë‚˜ ì„¤ëª…]
        - [ì¤‘ìš”í•œ ê°œë…]
        
        ### ì£¼ì œ 2: [ì œëª©]
        - [ìƒì„¸ ë‚´ìš©]
        - [ì˜ˆì‹œë‚˜ ì„¤ëª…]
        
        ## ğŸ”‘ ë‹¨ì„œ ì˜ì—­ (Cue Column)
        - **í•µì‹¬ í‚¤ì›Œë“œ**: [í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, ...]
        - **ì¤‘ìš” ì§ˆë¬¸**: 
          - [ì§ˆë¬¸1]
          - [ì§ˆë¬¸2]
        - **ê¸°ì–µí•  ì **: [ì¤‘ìš” í¬ì¸íŠ¸]
        - **ì—°ê´€ ê°œë…**: [ê´€ë ¨ ê°œë…ë“¤]
        
        ## ğŸ“Œ ìš”ì•½ ì˜ì—­ (Summary)
        [ì „ì²´ ë‚´ìš©ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ ìš”ì•½]
        
        í…ìŠ¤íŠ¸:
        {text[:3500]}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2000,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ì½”ë„¬ ë…¸íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ğŸ†• ê°œì„ ëœ ì½”ë„¬ ë…¸íŠ¸ ìƒì„± í•¨ìˆ˜
def generate_cornell_notes_advanced(text, style="standard", include_questions=True):
    """
    ì½”ë„¬ ë…¸íŠ¸ í•„ê¸°ë²•ì— ë”°ë¥¸ ê³ ê¸‰ ë…¸íŠ¸ ìƒì„±
    - style: standard, detailed, exam_focused
    - include_questions: ë³µìŠµ ì§ˆë¬¸ í¬í•¨ ì—¬ë¶€
    """
    try:
        client = openai.OpenAI()
        
        # ìŠ¤íƒ€ì¼ë³„ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        style_instructions = {
            "standard": "ê· í˜•ì¡íŒ êµ¬ì„±ìœ¼ë¡œ í•µì‹¬ ë‚´ìš©ê³¼ ì„¸ë¶€ì‚¬í•­ì„ ì ì ˆíˆ í¬í•¨",
            "detailed": "ìƒì„¸í•œ ì„¤ëª…ê³¼ ì˜ˆì‹œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ê¹Šì´ ìˆëŠ” ë‚´ìš© êµ¬ì„±",
            "exam_focused": "ì‹œí—˜ì— ë‚˜ì˜¬ ë§Œí•œ í•µì‹¬ ê°œë…ê³¼ ì¤‘ìš” í¬ì¸íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±"
        }
        
        questions_instruction = """
        - **ë³µìŠµ ì§ˆë¬¸**: 
          - [ë‚´ìš©ì„ ì´í•´í–ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ì§ˆë¬¸]
          - [ì‘ìš© ë¬¸ì œë‚˜ ì‚¬ê³  ì§ˆë¬¸]
          - [ì—°ê´€ ê°œë…ê³¼ì˜ ê´€ê³„ë¥¼ ë¬»ëŠ” ì§ˆë¬¸]
        """ if include_questions else ""
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ì½”ë„¬ ë…¸íŠ¸ í•„ê¸°ë²•(Cornell Note-Taking System)ì— ë”°ë¼ ì •ë¦¬í•´ì£¼ì„¸ìš”.
        
        **ì‘ì„± ìŠ¤íƒ€ì¼**: {style_instructions[style]}
        
        **ì½”ë„¬ ë…¸íŠ¸ êµ¬ì„± ì›ì¹™**:
        1. ë…¸íŠ¸ ì˜ì—­(60%): ê°•ì˜/ì½ê¸° ì¤‘ ê¸°ë¡í•˜ëŠ” ì£¼ìš” ë‚´ìš©
        2. ë‹¨ì„œ ì˜ì—­(20%): ë³µìŠµ ì‹œ ì‚¬ìš©í•  í‚¤ì›Œë“œì™€ íŒíŠ¸
        3. ìš”ì•½ ì˜ì—­(20%): ì „ì²´ ë‚´ìš©ì˜ í•µì‹¬ ìš”ì•½
        
        **ì¶œë ¥ í˜•ì‹**:
        
        # ğŸ“ ì½”ë„¬ ë…¸íŠ¸ - [ì£¼ì œëª…]
        
        ---
        
        ## ğŸ“‹ ë…¸íŠ¸ ì˜ì—­ (Note-taking Area)
        
        ### 1. [ì£¼ìš” ì£¼ì œ 1]
        - **ì •ì˜**: [í•µì‹¬ ê°œë… ì •ì˜]
        - **íŠ¹ì§•**: [ì£¼ìš” íŠ¹ì§•ë“¤]
        - **ì˜ˆì‹œ**: [êµ¬ì²´ì  ì˜ˆì‹œ]
        - **ì¤‘ìš”ì‚¬í•­**: [ê¸°ì–µí•´ì•¼ í•  ì ]
        
        ### 2. [ì£¼ìš” ì£¼ì œ 2]
        - **ê°œë…**: [í•µì‹¬ ê°œë…]
        - **ì›ë¦¬**: [ì‘ë™ ì›ë¦¬ë‚˜ ê³¼ì •]
        - **ì‘ìš©**: [ì‹¤ì œ ì ìš© ì‚¬ë¡€]
        
        ### 3. [ì£¼ìš” ì£¼ì œ 3]
        - **ë‚´ìš©**: [ìƒì„¸ ë‚´ìš©]
        - **ê´€ë ¨ì„±**: [ë‹¤ë¥¸ ê°œë…ê³¼ì˜ ì—°ê´€ì„±]
        
        ---
        
        ## ğŸ”‘ ë‹¨ì„œ ì˜ì—­ (Cue Column)
        
        **í•µì‹¬ í‚¤ì›Œë“œ**: [í‚¤ì›Œë“œ1], [í‚¤ì›Œë“œ2], [í‚¤ì›Œë“œ3]
        
        **ê¸°ì–µ ë‹¨ì„œ**: 
        - [ê¸°ì–µí•˜ê¸° ì‰¬ìš´ ë‹¨ì„œë‚˜ ì—°ìƒë²•]
        - [ì¤‘ìš”í•œ ê³µì‹ì´ë‚˜ ë²•ì¹™]
        
        **ì¤‘ìš” í¬ì¸íŠ¸**: 
        - [ì‹œí—˜ì— ë‚˜ì˜¬ ë§Œí•œ ë‚´ìš©]
        - [ë°˜ë“œì‹œ ê¸°ì–µí•´ì•¼ í•  ì‚¬ì‹¤]
        
        {questions_instruction}
        
        ---
        
        ## ğŸ“Œ ìš”ì•½ ì˜ì—­ (Summary)
        
        [ì „ì²´ ë‚´ìš©ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½. ë‚˜ì¤‘ì— ë¹ ë¥¸ ë³µìŠµìš©ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê°€ì¥ ì¤‘ìš”í•œ ë‚´ìš©ë§Œ í¬í•¨]
        
        ---
        
        í…ìŠ¤íŠ¸:
        {text[:4000]}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2500,
            temperature=0.2
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ì½”ë„¬ ë…¸íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ğŸ†• ì½”ë„¬ ë…¸íŠ¸ HTML í…œí”Œë¦¿ ìƒì„± (ì¸ì‡„ìš©)
def generate_cornell_notes_html(cornell_content, title="í•™ìŠµ ë…¸íŠ¸"):
    html_template = f"""
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>{title} - ì½”ë„¬ ë…¸íŠ¸</title>
        <style>
            body {{
                font-family: 'Malgun Gothic', Arial, sans-serif;
                margin: 20px;
                line-height: 1.6;
                color: #333;
            }}
            .cornell-container {{
                max-width: 800px;
                margin: 0 auto;
                border: 2px solid #333;
                min-height: 600px;
            }}
            .header {{
                border-bottom: 2px solid #333;
                padding: 10px;
                background-color: #f8f9fa;
                text-align: center;
            }}
            .main-content {{
                display: flex;
                min-height: 500px;
            }}
            .cue-column {{
                width: 30%;
                border-right: 2px solid #333;
                padding: 15px;
                background-color: #fff8dc;
            }}
            .note-area {{
                width: 70%;
                padding: 15px;
                background-color: white;
            }}
            .summary-area {{
                border-top: 2px solid #333;
                padding: 15px;
                background-color: #f0f8ff;
                min-height: 80px;
            }}
            h1, h2, h3 {{
                color: #2c3e50;
                margin-top: 0;
            }}
            .cue-column h3 {{
                color: #e74c3c;
                font-size: 14px;
                margin-bottom: 8px;
            }}
            .note-area h3 {{
                color: #3498db;
                border-bottom: 1px solid #3498db;
                padding-bottom: 5px;
            }}
            ul, ol {{
                margin: 10px 0;
                padding-left: 20px;
            }}
            .keyword {{
                background-color: #fff3cd;
                padding: 2px 6px;
                border-radius: 3px;
                font-weight: bold;
            }}
            .question {{
                color: #dc3545;
                font-style: italic;
            }}
            @media print {{
                body {{ margin: 0; }}
                .cornell-container {{ border: 1px solid #000; }}
            }}
        </style>
    </head>
    <body>
        <div class="cornell-container">
            <div class="header">
                <h1>ğŸ“ {title}</h1>
                <p>ë‚ ì§œ: ___________  ê³¼ëª©: ___________</p>
            </div>
            
            <div class="main-content">
                <div class="cue-column">
                    <h2>ğŸ”‘ ë‹¨ì„œ</h2>
                    <div id="cue-content">
                        <!-- ë‹¨ì„œ ë‚´ìš©ì´ ì—¬ê¸°ì— ë“¤ì–´ê°‘ë‹ˆë‹¤ -->
                    </div>
                </div>
                
                <div class="note-area">
                    <h2>ğŸ“‹ ë…¸íŠ¸</h2>
                    <div id="note-content">
                        <!-- ë…¸íŠ¸ ë‚´ìš©ì´ ì—¬ê¸°ì— ë“¤ì–´ê°‘ë‹ˆë‹¤ -->
                    </div>
                </div>
            </div>
            
            <div class="summary-area">
                <h2>ğŸ“Œ ìš”ì•½</h2>
                <div id="summary-content">
                    <!-- ìš”ì•½ ë‚´ìš©ì´ ì—¬ê¸°ì— ë“¤ì–´ê°‘ë‹ˆë‹¤ -->
                </div>
            </div>
        </div>
        
        <script>
            // ë§ˆí¬ë‹¤ìš´ ë‚´ìš©ì„ íŒŒì‹±í•˜ì—¬ ì ì ˆí•œ ì˜ì—­ì— ë°°ì¹˜
            const content = `{cornell_content}`;
            
            // ê°„ë‹¨í•œ ë§ˆí¬ë‹¤ìš´ íŒŒì‹±
            function parseContent(content) {{
                const lines = content.split('\\n');
                let currentSection = '';
                let noteContent = '';
                let cueContent = '';
                let summaryContent = '';
                
                for (let line of lines) {{
                    if (line.includes('ë…¸íŠ¸ ì˜ì—­') || line.includes('Note-taking Area')) {{
                        currentSection = 'note';
                    }} else if (line.includes('ë‹¨ì„œ ì˜ì—­') || line.includes('Cue Column')) {{
                        currentSection = 'cue';
                    }} else if (line.includes('ìš”ì•½ ì˜ì—­') || line.includes('Summary')) {{
                        currentSection = 'summary';
                    }} else if (line.trim() && !line.startsWith('#')) {{
                        if (currentSection === 'note') {{
                            noteContent += line + '<br>';
                        }} else if (currentSection === 'cue') {{
                            cueContent += line + '<br>';
                        }} else if (currentSection === 'summary') {{
                            summaryContent += line + '<br>';
                        }}
                    }}
                }}
                
                document.getElementById('note-content').innerHTML = noteContent;
                document.getElementById('cue-content').innerHTML = cueContent;
                document.getElementById('summary-content').innerHTML = summaryContent;
            }}
            
            parseContent(content);
        </script>
    </body>
    </html>
    """
    
    return html_template

# ğŸ†• ê°œì„ ëœ ì½”ë„¬ ë…¸íŠ¸ HTML ìƒì„±
def generate_cornell_notes_html_advanced(cornell_content, title="ì½”ë„¬ ë…¸íŠ¸"):
    """ì‹¤ì œ ì½”ë„¬ ë…¸íŠ¸ í˜•ì‹ì— ë§ëŠ” HTML ìƒì„±"""
    
    # ë‚´ìš© íŒŒì‹±
    sections = {'notes': '', 'cue': '', 'summary': ''}
    lines = cornell_content.split('\n')
    current_section = None
    
    for line in lines:
        if 'ë…¸íŠ¸ ì˜ì—­' in line or 'Note-taking Area' in line:
            current_section = 'notes'
        elif 'ë‹¨ì„œ ì˜ì—­' in line or 'Cue Column' in line:
            current_section = 'cue'
        elif 'ìš”ì•½ ì˜ì—­' in line or 'Summary' in line:
            current_section = 'summary'
        elif current_section and line.strip() and not line.startswith('#') and not line.startswith('---'):
            sections[current_section] += line + '\n'
    
    # HTML í…œí”Œë¦¿
    html_template = f"""
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>{title}</title>
        <style>
            @page {{
                size: A4;
                margin: 1cm;
            }}
            
            body {{
                font-family: 'Malgun Gothic', Arial, sans-serif;
                margin: 0;
                padding: 0;
                line-height: 1.6;
                color: #333;
            }}
            
            .cornell-container {{
                width: 100%;
                height: 100vh;
                border: 3px solid #000;
                display: flex;
                flex-direction: column;
            }}
            
            .cornell-header {{
                background-color: #f8f9fa;
                border-bottom: 2px solid #000;
                padding: 15px;
                text-align: center;
            }}
            
            .cornell-main {{
                display: flex;
                flex: 1;
            }}
            
            .cornell-cue {{
                width: 25%;
                border-right: 2px solid #000;
                padding: 15px;
                background-color: #fff8dc;
                font-size: 0.9rem;
            }}
            
            .cornell-notes {{
                width: 75%;
                padding: 15px;
                background-color: white;
            }}
            
            .cornell-summary {{
                border-top: 2px solid #000;
                padding: 15px;
                background-color: #e7f3ff;
                min-height: 100px;
            }}
        </style>
    </head>
    <body>
        <div class="cornell-container">
            <div class="cornell-header">
                <h1>ğŸ“ {title}</h1>
                <div>ìƒì„±ì¼: {datetime.datetime.now().strftime('%Yë…„ %mì›” %dì¼')}</div>
            </div>
            
            <div class="cornell-main">
                <div class="cornell-cue">
                    <h3>ğŸ”‘ ë‹¨ì„œ ì˜ì—­</h3>
                    <div>{sections['cue']}</div>
                </div>
                
                <div class="cornell-notes">
                    <h3>ğŸ“‹ ë…¸íŠ¸ ì˜ì—­</h3>
                    <div>{sections['notes']}</div>
                </div>
            </div>
            
            <div class="cornell-summary">
                <h3>ğŸ“Œ ìš”ì•½ ì˜ì—­</h3>
                <div>{sections['summary']}</div>
            </div>
        </div>
    </body>
    </html>
    """
    
    return html_template

# ğŸ†• í”Œë˜ì‹œì¹´ë“œ ìƒì„± ê¸°ëŠ¥
def generate_flashcards(text, num_cards=10):
    try:
        # í…ìŠ¤íŠ¸ ìœ íš¨ì„± ê²€ì‚¬
        if not text or len(text.strip()) < 100:
            return "í”Œë˜ì‹œì¹´ë“œë¥¼ ìƒì„±í•˜ê¸°ì— í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë” ë§ì€ ë‚´ìš©ì´ í•„ìš”í•©ë‹ˆë‹¤."
        
        # API í‚¤ í™•ì¸
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        client = openai.OpenAI(api_key=api_key)
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ì•ˆì „í•˜ê²Œ)
        safe_text = text[:3000] if len(text) > 3000 else text
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ {num_cards}ê°œì˜ í•™ìŠµ í”Œë˜ì‹œì¹´ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        ê° ì¹´ë“œëŠ” ì•ë©´(ì§ˆë¬¸/ê°œë…)ê³¼ ë’·ë©´(ë‹µë³€/ì„¤ëª…)ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
        
        í˜•ì‹:
        ì¹´ë“œ 1:
        ì•ë©´: [í•µì‹¬ ê°œë…ì´ë‚˜ ì§ˆë¬¸]
        ë’·ë©´: [ìƒì„¸í•œ ì„¤ëª…ì´ë‚˜ ë‹µë³€]
        
        ì¹´ë“œ 2:
        ì•ë©´: [í•µì‹¬ ê°œë…ì´ë‚˜ ì§ˆë¬¸]
        ë’·ë©´: [ìƒì„¸í•œ ì„¤ëª…ì´ë‚˜ ë‹µë³€]
        
        í”Œë˜ì‹œì¹´ë“œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ìœ í˜•ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”:
        - ì •ì˜ ì•”ê¸° (ê°œë… â†’ ì •ì˜)
        - ê³µì‹ ì•”ê¸° (ê³µì‹ëª… â†’ ê³µì‹)
        - ì˜ˆì‹œ ë¬¸ì œ (ë¬¸ì œ â†’ í•´ë‹µ)
        - í•µì‹¬ í‚¤ì›Œë“œ (í‚¤ì›Œë“œ â†’ ì„¤ëª…)
        
        í…ìŠ¤íŠ¸:
        {safe_text}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2000,
            temperature=0.4
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"í”Œë˜ì‹œì¹´ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ğŸ†• ì§ì ‘ ë‹µë³€ ìƒì„± (ì²´ì¸ ì‹¤íŒ¨ ì‹œ ëŒ€ì•ˆ)
def generate_direct_answer(text, question):
    """ë²¡í„°ìŠ¤í† ì–´ ì—†ì´ ì§ì ‘ í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
    try:
        client = openai.OpenAI()
        
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ê´€ë ¨ ë¶€ë¶„ë§Œ ì¶”ì¶œ
        relevant_text = text[:4000] if len(text) > 4000 else text
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
        
        í…ìŠ¤íŠ¸:
        {relevant_text}
        
        ì§ˆë¬¸: {question}
        
        ë‹µë³€:
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1000,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ğŸ†• ê°„ë‹¨í•œ ë‹µë³€ ìƒì„± (ìµœì¢… ëŒ€ì•ˆ)
def generate_simple_answer(text, question):
    """ê°€ì¥ ê¸°ë³¸ì ì¸ í…ìŠ¤íŠ¸ ë§¤ì¹­ ê¸°ë°˜ ë‹µë³€"""
    try:
        # ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        question_lower = question.lower()
        text_lower = text.lower()
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
        keywords = [word for word in question_lower.split() if len(word) > 2]
        
        # ê´€ë ¨ ë¬¸ì¥ ì°¾ê¸°
        sentences = text.split('.')
        relevant_sentences = []
        
        for sentence in sentences:
            sentence_lower = sentence.lower()
            if any(keyword in sentence_lower for keyword in keywords):
                relevant_sentences.append(sentence.strip())
                if len(relevant_sentences) >= 3:  # ìµœëŒ€ 3ê°œ ë¬¸ì¥
                    break
        
        if relevant_sentences:
            return " ".join(relevant_sentences)
        else:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”."
    
    except Exception as e:
        return f"ê¸°ë³¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}"

# ğŸ†• ì‚¬ìš©ìë³„ í•™ìŠµ ì´ë ¥ ê´€ë¦¬
def save_user_study_history(username, question, answer, topic="ì¼ë°˜"):
    """ì‚¬ìš©ìë³„ í•™ìŠµ ì´ë ¥ ì €ì¥"""
    try:
        os.makedirs("users", exist_ok=True)
        history_file = f"users/{username}_history.json"
        
        # ê¸°ì¡´ ì´ë ¥ ë¡œë“œ
        try:
            with open(history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)
        except FileNotFoundError:
            history = []
        
        # ìƒˆ ê¸°ë¡ ì¶”ê°€
        new_record = {
            "timestamp": datetime.datetime.now().isoformat(),
            "question": question,
            "answer": answer[:300] + "..." if len(answer) > 300 else answer,
            "topic": topic
        }
        
        history.append(new_record)
        
        # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
        if len(history) > 100:
            history = history[-100:]
        
        # ì €ì¥
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        print(f"ì‚¬ìš©ì ì´ë ¥ ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

def load_user_study_history(username):
    """ì‚¬ìš©ìë³„ í•™ìŠµ ì´ë ¥ ë¡œë“œ"""
    try:
        history_file = f"users/{username}_history.json"
        with open(history_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return []
    except Exception as e:
        print(f"ì‚¬ìš©ì ì´ë ¥ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return []

def update_user_activity(username, activity_type, data=None):
    """ì‚¬ìš©ì í™œë™ ì—…ë°ì´íŠ¸"""
    try:
        os.makedirs("users", exist_ok=True)
        activity_file = f"users/{username}_activity.json"
        
        # ê¸°ì¡´ í™œë™ ë¡œë“œ
        try:
            with open(activity_file, 'r', encoding='utf-8') as f:
                activity = json.load(f)
        except FileNotFoundError:
            activity = {
                "username": username,
                "total_questions": 0,
                "total_pdfs": 0,
                "total_quizzes": 0,
                "last_activity": None,
                "activities": []
            }
        
        # í™œë™ ì—…ë°ì´íŠ¸
        if activity_type == "question_asked":
            activity["total_questions"] += 1
        elif activity_type == "pdf_processed":
            activity["total_pdfs"] += 1
        elif activity_type == "quiz_completed":
            activity["total_quizzes"] += 1
        
        activity["last_activity"] = datetime.datetime.now().isoformat()
        
        # í™œë™ ê¸°ë¡ ì¶”ê°€
        activity["activities"].append({
            "type": activity_type,
            "timestamp": datetime.datetime.now().isoformat(),
            "data": data
        })
        
        # ìµœê·¼ 50ê°œ í™œë™ë§Œ ìœ ì§€
        if len(activity["activities"]) > 50:
            activity["activities"] = activity["activities"][-50:]
        
        # ì €ì¥
        with open(activity_file, 'w', encoding='utf-8') as f:
            json.dump(activity, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        print(f"ì‚¬ìš©ì í™œë™ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
        return False

def calculate_user_progress(history, username):
    """ì‚¬ìš©ìë³„ í•™ìŠµ ì§„í–‰ë¥  ê³„ì‚°"""
    if not history:
        return 0, {}, {}
    
    # ì£¼ì œë³„ ì§ˆë¬¸ ìˆ˜ ê³„ì‚°
    topics = {}
    for record in history:
        topic = record.get('topic', 'ì¼ë°˜')
        topics[topic] = topics.get(topic, 0) + 1
    
    # ì§„í–‰ë¥  ê³„ì‚° (ì§ˆë¬¸ ìˆ˜ ê¸°ë°˜)
    total_questions = len(history)
    progress_percentage = min(total_questions * 2, 100)  # 50ê°œ ì§ˆë¬¸ = 100%
    
    # í•™ìŠµ íŒ¨í„´ ë¶„ì„
    study_patterns = {
        "most_active_topic": max(topics.items(), key=lambda x: x[1])[0] if topics else "ì—†ìŒ",
        "total_topics": len(topics),
        "avg_questions_per_topic": total_questions / len(topics) if topics else 0
    }
    
    return progress_percentage, topics, study_patterns

def check_plan_limits(username, feature_type):
    """í”Œëœë³„ ê¸°ëŠ¥ ì œí•œ í™•ì¸"""
    # ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  ê¸°ëŠ¥ í—ˆìš© (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‚¬ìš©ì í”Œëœ í™•ì¸)
    return True, "ì‚¬ìš© ê°€ëŠ¥"

def generate_learning_recommendations(username, history):
    """í•™ìŠµ ì¶”ì²œ ìƒì„±"""
    try:
        if not history:
            return "ì•„ì§ í•™ìŠµ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì‹œì‘í•´ë³´ì„¸ìš”!"
        
        # ìµœê·¼ ì§ˆë¬¸ ë¶„ì„
        recent_questions = [record['question'] for record in history[-5:]]
        
        client = openai.OpenAI()
        prompt = f"""
        ë‹¤ìŒ ìµœê·¼ ì§ˆë¬¸ë“¤ì„ ë¶„ì„í•˜ì—¬ í•™ìŠµìì—ê²Œ ë§ì¶¤ ì¶”ì²œì„ í•´ì£¼ì„¸ìš”:
        
        ìµœê·¼ ì§ˆë¬¸ë“¤:
        {chr(10).join(recent_questions)}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”:
        1. í•™ìŠµ íŒ¨í„´ ë¶„ì„
        2. ì¶”ì²œ í•™ìŠµ ì£¼ì œ
        3. ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=500,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {str(e)}"

# ğŸ†• ì‚¬ìš©ì ê´€ë¦¬ ì‹œìŠ¤í…œ
def hash_password(password):
    """ë¹„ë°€ë²ˆí˜¸ í•´ì‹œí™”"""
    return hashlib.sha256(password.encode()).hexdigest()

def create_user(username, password, plan="free"):
    """ìƒˆ ì‚¬ìš©ì ìƒì„±"""
    try:
        os.makedirs("users", exist_ok=True)
        users_file = "users/users.json"
        
        # ê¸°ì¡´ ì‚¬ìš©ì ëª©ë¡ ë¡œë“œ
        try:
            with open(users_file, 'r', encoding='utf-8') as f:
                users = json.load(f)
        except FileNotFoundError:
            users = {}
        
        # ì‚¬ìš©ìëª… ì¤‘ë³µ í™•ì¸
        if username in users:
            return False
        
        # ìƒˆ ì‚¬ìš©ì ì¶”ê°€
        users[username] = {
            "username": username,
            "password": hash_password(password),
            "plan": plan,
            "created_at": datetime.datetime.now().isoformat(),
            "last_login": None,
            "usage_stats": {
                "total_questions": 0,
                "total_pdfs": 0,
                "total_quizzes": 0,
                "api_calls_today": 0,
                "last_api_call": None
            }
        }
        
        # ì €ì¥
        with open(users_file, 'w', encoding='utf-8') as f:
            json.dump(users, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        print(f"ì‚¬ìš©ì ìƒì„± ì˜¤ë¥˜: {e}")
        return False

def authenticate_user(username, password):
    """ì‚¬ìš©ì ì¸ì¦"""
    try:
        users_file = "users/users.json"
        with open(users_file, 'r', encoding='utf-8') as f:
            users = json.load(f)
        
        if username in users:
            stored_password = users[username]["password"]
            if stored_password == hash_password(password):
                # ë¡œê·¸ì¸ ì‹œê°„ ì—…ë°ì´íŠ¸
                users[username]["last_login"] = datetime.datetime.now().isoformat()
                
                with open(users_file, 'w', encoding='utf-8') as f:
                    json.dump(users, f, ensure_ascii=False, indent=2)
                
                return users[username]
        
        return None
    except FileNotFoundError:
        return None
    except Exception as e:
        print(f"ì¸ì¦ ì˜¤ë¥˜: {e}")
        return None

def check_plan_limits(username, feature_type):
    """í”Œëœë³„ ê¸°ëŠ¥ ì œí•œ í™•ì¸"""
    try:
        users_file = "users/users.json"
        with open(users_file, 'r', encoding='utf-8') as f:
            users = json.load(f)
        
        if username not in users:
            return False, "ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        user = users[username]
        plan = user.get("plan", "free")
        usage = user.get("usage_stats", {})
        
        # ë¬´ë£Œ í”Œëœ ì œí•œ
        if plan == "free":
            if feature_type == "pdf_upload":
                if usage.get("total_pdfs", 0) >= 10:  # ì¼ì¼ 10ê°œ ì œí•œ
                    return False, "ë¬´ë£Œ í”Œëœì€ ì¼ì¼ 10ê°œ PDF ì œí•œì…ë‹ˆë‹¤."
            elif feature_type == "quiz_generation":
                if usage.get("total_quizzes", 0) >= 5:  # ì¼ì¼ 5ê°œ ì œí•œ
                    return False, "ë¬´ë£Œ í”Œëœì€ ì¼ì¼ 5ê°œ í€´ì¦ˆ ì œí•œì…ë‹ˆë‹¤."
            elif feature_type == "multi_document":
                return False, "ë‹¤ì¤‘ ë¬¸ì„œ ê¸°ëŠ¥ì€ í”„ë¦¬ë¯¸ì—„ í”Œëœì´ í•„ìš”í•©ë‹ˆë‹¤."
            elif feature_type == "api_calls":
                today = datetime.datetime.now().date().isoformat()
                last_call = usage.get("last_api_call", "")
                if last_call.startswith(today):
                    if usage.get("api_calls_today", 0) >= 50:  # ì¼ì¼ 50íšŒ ì œí•œ
                        return False, "ë¬´ë£Œ í”Œëœì€ ì¼ì¼ 50íšŒ API í˜¸ì¶œ ì œí•œì…ë‹ˆë‹¤."
        
        return True, "ì‚¬ìš© ê°€ëŠ¥"
    except Exception as e:
        print(f"í”Œëœ ì œí•œ í™•ì¸ ì˜¤ë¥˜: {e}")
        return True, "í™•ì¸ ë¶ˆê°€"

def update_user_usage(username, feature_type):
    """ì‚¬ìš©ì ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸"""
    try:
        users_file = "users/users.json"
        with open(users_file, 'r', encoding='utf-8') as f:
            users = json.load(f)
        
        if username in users:
            usage = users[username].get("usage_stats", {})
            today = datetime.datetime.now().date().isoformat()
            
            # API í˜¸ì¶œ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
            last_call = usage.get("last_api_call", "")
            if last_call.startswith(today):
                usage["api_calls_today"] = usage.get("api_calls_today", 0) + 1
            else:
                usage["api_calls_today"] = 1
            
            usage["last_api_call"] = datetime.datetime.now().isoformat()
            
            # ê¸°ëŠ¥ë³„ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
            if feature_type == "pdf_upload":
                usage["total_pdfs"] = usage.get("total_pdfs", 0) + 1
            elif feature_type == "quiz_generation":
                usage["total_quizzes"] = usage.get("total_quizzes", 0) + 1
            elif feature_type == "question_asked":
                usage["total_questions"] = usage.get("total_questions", 0) + 1
            
            users[username]["usage_stats"] = usage
            
            with open(users_file, 'w', encoding='utf-8') as f:
                json.dump(users, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        print(f"ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
        return False

# ğŸ†• ì±— ê¸°ë¡ ê´€ë¦¬
def save_chat_message(username, message, response, message_type="qa"):
    """ì±— ë©”ì‹œì§€ ì €ì¥"""
    try:
        os.makedirs("users", exist_ok=True)
        chat_file = f"users/{username}_chat.json"
        
        # ê¸°ì¡´ ì±— ê¸°ë¡ ë¡œë“œ
        try:
            with open(chat_file, 'r', encoding='utf-8') as f:
                chat_history = json.load(f)
        except FileNotFoundError:
            chat_history = []
        
        # ìƒˆ ë©”ì‹œì§€ ì¶”ê°€
        new_message = {
            "timestamp": datetime.datetime.now().isoformat(),
            "message": message,
            "response": response[:500] + "..." if len(response) > 500 else response,
            "type": message_type
        }
        
        chat_history.append(new_message)
        
        # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
        if len(chat_history) > 100:
            chat_history = chat_history[-100:]
        
        # ì €ì¥
        with open(chat_file, 'w', encoding='utf-8') as f:
            json.dump(chat_history, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        print(f"ì±— ê¸°ë¡ ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

def load_chat_history(username):
    """ì±— ê¸°ë¡ ë¡œë“œ"""
    try:
        chat_file = f"users/{username}_chat.json"
        with open(chat_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return []
    except Exception as e:
        print(f"ì±— ê¸°ë¡ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return []

# ğŸ†• ë‹¤ì¤‘ ë²¡í„°ìŠ¤í† ì–´ ê´€ë¦¬
class MultiVectorStoreManager:
    def __init__(self):
        self.vectorstores = {}
        self.document_mapping = {}
    
    def add_document(self, doc_name, text):
        """ê°œë³„ ë¬¸ì„œì˜ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±"""
        try:
            vectorstore = create_vectorstore(text)
            if vectorstore:
                self.vectorstores[doc_name] = vectorstore
                self.document_mapping[doc_name] = len(text)
                return True
            return False
        except Exception as e:
            print(f"ë¬¸ì„œ ì¶”ê°€ ì˜¤ë¥˜: {e}")
            return False
    
    def search_across_documents(self, query, k=5):
        """ëª¨ë“  ë¬¸ì„œì—ì„œ ê²€ìƒ‰"""
        results = []
        for doc_name, vectorstore in self.vectorstores.items():
            try:
                docs = vectorstore.similarity_search(query, k=k//len(self.vectorstores) + 1)
                for doc in docs:
                    results.append({
                        "content": doc.page_content,
                        "source": doc_name,
                        "score": 0  # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
                    })
            except Exception as e:
                print(f"ê²€ìƒ‰ ì˜¤ë¥˜ ({doc_name}): {e}")
        
        return results[:k]
    
    def get_document_stats(self):
        """ë¬¸ì„œ í†µê³„ ë°˜í™˜"""
        return {
            "total_documents": len(self.vectorstores),
            "document_sizes": self.document_mapping,
            "total_size": sum(self.document_mapping.values())
        }

# ì „ì—­ ë²¡í„°ìŠ¤í† ì–´ ë§¤ë‹ˆì €
vector_manager = MultiVectorStoreManager()

# ğŸ†• í”Œë˜ì‹œì¹´ë“œ HTML ìƒì„± (ì¸í„°ë™í‹°ë¸Œ)
def generate_flashcards_html(flashcards_content, title="í•™ìŠµ í”Œë˜ì‹œì¹´ë“œ"):
    # í”Œë˜ì‹œì¹´ë“œ ë‚´ìš© íŒŒì‹±
    cards = []
    lines = flashcards_content.split('\n')
    current_card = {}
    
    try:
        for line in lines:
            line = line.strip()
            if line.startswith('ì¹´ë“œ') and ':' in line:
                if current_card and 'front' in current_card and 'back' in current_card:
                    cards.append(current_card)
                current_card = {}
            elif line.startswith('ì•ë©´:'):
                current_card['front'] = line.replace('ì•ë©´:', '').strip()
            elif line.startswith('ë’·ë©´:'):
                current_card['back'] = line.replace('ë’·ë©´:', '').strip()
        
        # ë§ˆì§€ë§‰ ì¹´ë“œ ì¶”ê°€
        if current_card and 'front' in current_card and 'back' in current_card:
            cards.append(current_card)
        
        # ì¹´ë“œê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì¹´ë“œ ìƒì„±
        if not cards:
            cards = [{'front': 'í”Œë˜ì‹œì¹´ë“œ ìƒì„± ì‹¤íŒ¨', 'back': 'ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”'}]
    
    except Exception as e:
        cards = [{'front': 'íŒŒì‹± ì˜¤ë¥˜', 'back': f'ì˜¤ë¥˜: {str(e)}'}]
    
    # HTML í…œí”Œë¦¿
    html_template = f"""
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>{title}</title>
        <style>
            body {{
                font-family: 'Malgun Gothic', Arial, sans-serif;
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                margin: 0;
                padding: 20px;
                min-height: 100vh;
            }}
            
            .container {{
                max-width: 800px;
                margin: 0 auto;
                text-align: center;
            }}
            
            .header {{
                color: white;
                margin-bottom: 30px;
            }}
            
            .flashcard-container {{
                perspective: 1000px;
                margin: 20px auto;
                width: 400px;
                height: 250px;
            }}
            
            .flashcard {{
                position: relative;
                width: 100%;
                height: 100%;
                text-align: center;
                transition: transform 0.6s;
                transform-style: preserve-3d;
                cursor: pointer;
            }}
            
            .flashcard.flipped {{
                transform: rotateY(180deg);
            }}
            
            .card-face {{
                position: absolute;
                width: 100%;
                height: 100%;
                backface-visibility: hidden;
                border-radius: 15px;
                box-shadow: 0 8px 16px rgba(0,0,0,0.3);
                display: flex;
                align-items: center;
                justify-content: center;
                padding: 20px;
                box-sizing: border-box;
            }}
            
            .card-front {{
                background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 100%);
                color: #333;
            }}
            
            .card-back {{
                background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
                color: #333;
                transform: rotateY(180deg);
            }}
            
            .card-content {{
                font-size: 18px;
                line-height: 1.4;
                word-break: keep-all;
            }}
            
            .controls {{
                margin: 30px 0;
            }}
            
            .btn {{
                background: rgba(255,255,255,0.2);
                color: white;
                border: 2px solid white;
                padding: 12px 24px;
                margin: 0 10px;
                border-radius: 25px;
                cursor: pointer;
                font-size: 16px;
                transition: all 0.3s;
            }}
            
            .btn:hover {{
                background: white;
                color: #667eea;
            }}
            
            .progress {{
                color: white;
                font-size: 18px;
                margin: 20px 0;
            }}
            
            .card-indicator {{
                color: white;
                font-size: 14px;
                margin-top: 10px;
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>ğŸ´ {title}</h1>
                <p>ì¹´ë“œë¥¼ í´ë¦­í•˜ë©´ ë’¤ì§‘ì–´ì§‘ë‹ˆë‹¤</p>
            </div>
            
            <div class="progress">
                <span id="current-card">1</span> / <span id="total-cards">{len(cards)}</span>
            </div>
            
            <div class="flashcard-container">
                <div class="flashcard" id="flashcard" onclick="flipCard()">
                    <div class="card-face card-front">
                        <div class="card-content" id="front-content">
                            {cards[0]['front'] if cards else 'ì¹´ë“œê°€ ì—†ìŠµë‹ˆë‹¤'}
                        </div>
                    </div>
                    <div class="card-face card-back">
                        <div class="card-content" id="back-content">
                            {cards[0]['back'] if cards else ''}
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="card-indicator">
                ğŸ’¡ ì¹´ë“œë¥¼ í´ë¦­í•´ì„œ ë‹µì„ í™•ì¸í•˜ì„¸ìš”
            </div>
            
            <div class="controls">
                <button class="btn" onclick="previousCard()">â¬…ï¸ ì´ì „</button>
                <button class="btn" onclick="flipCard()">ğŸ”„ ë’¤ì§‘ê¸°</button>
                <button class="btn" onclick="nextCard()">ë‹¤ìŒ â¡ï¸</button>
            </div>
            
            <div class="controls">
                <button class="btn" onclick="shuffleCards()">ğŸ”€ ì„ê¸°</button>
                <button class="btn" onclick="resetCards()">ğŸ”„ ì²˜ìŒë¶€í„°</button>
            </div>
        </div>
        
        <script>
            const cards = {cards};
            let currentIndex = 0;
            let isFlipped = false;
            
            function updateCard() {{
                const frontContent = document.getElementById('front-content');
                const backContent = document.getElementById('back-content');
                const currentCardSpan = document.getElementById('current-card');
                
                if (cards[currentIndex]) {{
                    frontContent.textContent = cards[currentIndex].front;
                    backContent.textContent = cards[currentIndex].back;
                    currentCardSpan.textContent = currentIndex + 1;
                }}
                
                // ì¹´ë“œ ë’¤ì§‘ê¸° ìƒíƒœ ì´ˆê¸°í™”
                const flashcard = document.getElementById('flashcard');
                flashcard.classList.remove('flipped');
                isFlipped = false;
            }}
            
            function flipCard() {{
                const flashcard = document.getElementById('flashcard');
                flashcard.classList.toggle('flipped');
                isFlipped = !isFlipped;
            }}
            
            function nextCard() {{
                if (currentIndex < cards.length - 1) {{
                    currentIndex++;
                    updateCard();
                }}
            }}
            
            function previousCard() {{
                if (currentIndex > 0) {{
                    currentIndex--;
                    updateCard();
                }}
            }}
            
            function shuffleCards() {{
                for (let i = cards.length - 1; i > 0; i--) {{
                    const j = Math.floor(Math.random() * (i + 1));
                    [cards[i], cards[j]] = [cards[j], cards[i]];
                }}
                currentIndex = 0;
                updateCard();
            }}
            
            function resetCards() {{
                currentIndex = 0;
                updateCard();
            }}
            
            // í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤
            document.addEventListener('keydown', function(event) {{
                switch(event.key) {{
                    case 'ArrowLeft':
                        previousCard();
                        break;
                    case 'ArrowRight':
                        nextCard();
                        break;
                    case ' ':
                        event.preventDefault();
                        flipCard();
                        break;
                }}
            }});
        </script>
    </body>
    </html>
    """
    
    return html_template

# ğŸ†• ì‚¬ìš©ì ë§ì¶¤ í•™ìŠµ ì´ë ¥ ê´€ë¦¬
def load_user_study_history(username, filename_prefix="user_history"):
    """ì§€ì‹ ì¹´ë“œ ì—…ë°ì´íŠ¸"""
    try:
        # ìˆœí™˜ import ë°©ì§€ë¥¼ ìœ„í•´ í•¨ìˆ˜ë“¤ì„ ì—¬ê¸°ì„œ ì§ì ‘ êµ¬í˜„
        def create_knowledge_card_local(pdf_name: str, upload_date: str, question_count: int, last_study: str):
            return {
                "pdf_name": pdf_name,
                "upload_date": upload_date,
                "question_count": question_count,
                "last_study": last_study,
                "card_id": f"card_{pdf_name.replace('.pdf', '').replace(' ', '_')}"
            }
        
        def load_knowledge_cards_local(username: str = None):
            try:
                if username:
                    cards_file = f"users/{username}_knowledge_cards.json"
                else:
                    cards_file = "knowledge_cards.json"
                
                if os.path.exists(cards_file):
                    with open(cards_file, 'r', encoding='utf-8') as f:
                        return json.load(f)
                return []
            except:
                return []
        
        def save_knowledge_cards_local(cards, username: str = None):
            try:
                if username:
                    cards_file = f"users/{username}_knowledge_cards.json"
                    os.makedirs("users", exist_ok=True)
                else:
                    cards_file = "knowledge_cards.json"
                
                with open(cards_file, 'w', encoding='utf-8') as f:
                    json.dump(cards, f, ensure_ascii=False, indent=2)
                return True
            except:
                return False
        
        cards = load_knowledge_cards_local(username)
        
        # ê¸°ì¡´ ì¹´ë“œ ì°¾ê¸°
        existing_card = None
        for i, card in enumerate(cards):
            if card['pdf_name'] == pdf_name:
                existing_card = i
                break
        
        # ì¹´ë“œ ì—…ë°ì´íŠ¸ ë˜ëŠ” ìƒì„±
        if existing_card is not None:
            cards[existing_card]['question_count'] += 1
            cards[existing_card]['last_study'] = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
        else:
            new_card = create_knowledge_card_local(
                pdf_name=pdf_name,
                upload_date=datetime.datetime.now().strftime("%Y-%m-%d"),
                question_count=1,
                last_study=datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
            )
            cards.append(new_card)
        
        save_knowledge_cards_local(cards, username)
        return True
    except Exception as e:
        print(f"ì§€ì‹ ì¹´ë“œ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
        return False

# ğŸ†• ì‚¬ìš©ì ë§ì¶¤ í•™ìŠµ ì´ë ¥ ê´€ë¦¬
def load_user_study_history(username, filename_prefix="user_history"):
    """ì‚¬ìš©ìë³„ í•™ìŠµ ì´ë ¥ ë¡œë“œ"""
    filename = f"{filename_prefix}_{username}.json"
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return []
    except Exception as e:
        print(f"ì‚¬ìš©ì ì´ë ¥ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return []

def save_user_study_history(username, question, answer, topic=None, difficulty=None, filename_prefix="user_history"):
    """ì‚¬ìš©ìë³„ í•™ìŠµ ì´ë ¥ ì €ì¥"""
    filename = f"{filename_prefix}_{username}.json"
    try:
        # ê¸°ì¡´ ì´ë ¥ ë¡œë“œ
        history = load_user_study_history(username, filename_prefix)
        
        # ìƒˆ ê¸°ë¡ ì¶”ê°€
        new_record = {
            "timestamp": datetime.datetime.now().isoformat(),
            "question": question,
            "answer": answer[:200] + "..." if len(answer) > 200 else answer,
            "topic": topic,
            "difficulty": difficulty,
            "study_time": random.randint(30, 300)  # 30ì´ˆ-5ë¶„ ëœë¤
        }
        
        history.append(new_record)
        
        # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
        if len(history) > 100:
            history = history[-100:]
        
        # ì €ì¥
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
            
        return True
    except Exception as e:
        print(f"ì‚¬ìš©ì ì´ë ¥ ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

def calculate_user_progress(history, username):
    """ì‚¬ìš©ìë³„ ìƒì„¸ ì§„í–‰ë¥  ê³„ì‚°"""
    if not history:
        return 0, {}, {}
    
    # ê¸°ë³¸ ì§„í–‰ë¥  ê³„ì‚°
    topics = {}
    study_patterns = {
        'time_distribution': {},
        'difficulty_preference': {},
        'topic_interest': {}
    }
    
    for record in history:
        # ì£¼ì œë³„ ë¶„ë¥˜
        question = record['question'].lower()
        topic_found = False
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì£¼ì œ ë¶„ë¥˜
        topic_keywords = {
            'Chapter 1': ['1ì¥', 'ì²«ë²ˆì§¸', 'ì²˜ìŒ', 'chapter 1', 'ê¸°ì´ˆ'],
            'Chapter 2': ['2ì¥', 'ë‘ë²ˆì§¸', 'chapter 2', 'ì¤‘ê¸‰'],
            'Chapter 3': ['3ì¥', 'ì„¸ë²ˆì§¸', 'chapter 3', 'ê³ ê¸‰'],
            'ê°œë…': ['ê°œë…', 'ì •ì˜', 'ì˜ë¯¸', 'ëœ»'],
            'ê³µì‹': ['ê³µì‹', 'ìˆ˜ì‹', 'ê³„ì‚°', 'ì‹'],
            'ì˜ˆì œ': ['ì˜ˆì œ', 'ë¬¸ì œ', 'í’€ì´', 'í•´ë‹µ']
        }
        
        for topic, keywords in topic_keywords.items():
            if any(keyword in question for keyword in keywords):
                topics[topic] = topics.get(topic, 0) + 1
                topic_found = True
                break
        
        if not topic_found:
            topics['ê¸°íƒ€'] = topics.get('ê¸°íƒ€', 0) + 1
        
        # ì‹œê°„ íŒ¨í„´ ë¶„ì„
        timestamp = record['timestamp']
        hour = datetime.datetime.fromisoformat(timestamp).hour
        time_slot = f"{hour:02d}:00"
        study_patterns['time_distribution'][time_slot] = study_patterns['time_distribution'].get(time_slot, 0) + 1
        
        # ë‚œì´ë„ ì„ í˜¸ë„
        difficulty = record.get('difficulty', 'medium')
        study_patterns['difficulty_preference'][difficulty] = study_patterns['difficulty_preference'].get(difficulty, 0) + 1
    
    # ì§„í–‰ë¥  ê³„ì‚° (ë” ì •êµí•œ ë°©ì‹)
    total_chapters = 10
    progress_percentage = min(len(topics) / total_chapters * 100, 100)
    
    # í•™ìŠµ ì¼ê´€ì„± ë³´ë„ˆìŠ¤
    if len(history) > 20:
        progress_percentage += 10
    if len(set([record['timestamp'][:10] for record in history])) > 7:  # 7ì¼ ì´ìƒ í•™ìŠµ
        progress_percentage += 15
    
    progress_percentage = min(progress_percentage, 100)
    
    return progress_percentage, topics, study_patterns

def generate_learning_recommendations(username, history, current_topic=None):
    """AI ê¸°ë°˜ ë§ì¶¤ í•™ìŠµ ì¶”ì²œ"""
    try:
        client = openai.OpenAI()
        
        # ì‚¬ìš©ì í•™ìŠµ íŒ¨í„´ ë¶„ì„
        recent_questions = [record['question'] for record in history[-10:]]
        topics_studied = list(set([record.get('topic', 'ì¼ë°˜') for record in history]))
        
        prompt = f"""
        ì‚¬ìš©ì {username}ì˜ í•™ìŠµ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ë§ì¶¤ ì¶”ì²œì„ ìƒì„±í•´ì£¼ì„¸ìš”.
        
        ìµœê·¼ ì§ˆë¬¸ë“¤:
        {chr(10).join(recent_questions)}
        
        í•™ìŠµí•œ ì£¼ì œë“¤: {', '.join(topics_studied)}
        í˜„ì¬ í•™ìŠµ ì¤‘ì¸ ì£¼ì œ: {current_topic or 'ì—†ìŒ'}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”:
        1. ë³µìŠµì´ í•„ìš”í•œ ì˜ì—­
        2. ë‹¤ìŒ í•™ìŠµ ì¶”ì²œ ì£¼ì œ
        3. í•™ìŠµ ë°©ë²• ì œì•ˆ
        4. ì˜ˆìƒ ì†Œìš” ì‹œê°„
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=800,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ğŸ†• ì‚¬ìš©ì ê´€ë¦¬ ì‹œìŠ¤í…œ
import hashlib
import datetime

def create_user_profile(username, email, plan="free"):
    """ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„±"""
    user_data = {
        "username": username,
        "email": email,
        "plan": plan,  # free, premium, instructor
        "created_date": datetime.datetime.now().isoformat(),
        "pdf_count": 0,
        "quiz_count": 0,
        "study_time": 0,
        "achievements": [],
        "learning_streak": 0,
        "last_login": datetime.datetime.now().isoformat()
    }
    
    # ì‚¬ìš©ì íŒŒì¼ ì €ì¥
    user_file = f"users/{username}.json"
    os.makedirs("users", exist_ok=True)
    
    try:
        with open(user_file, 'w', encoding='utf-8') as f:
            json.dump(user_data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"ì‚¬ìš©ì ìƒì„± ì˜¤ë¥˜: {e}")
        return False

def load_user_profile(username):
    """ì‚¬ìš©ì í”„ë¡œí•„ ë¡œë“œ"""
    user_file = f"users/{username}.json"
    try:
        with open(user_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return None
    except Exception as e:
        print(f"ì‚¬ìš©ì ë¡œë“œ ì˜¤ë¥˜: {e}")
        return None

def update_user_activity(username, activity_type, data=None):
    """ì‚¬ìš©ì í™œë™ ì—…ë°ì´íŠ¸"""
    user_profile = load_user_profile(username)
    if not user_profile:
        return False
    
    # í™œë™ë³„ ì—…ë°ì´íŠ¸
    if activity_type == "pdf_processed":
        user_profile["pdf_count"] += 1
    elif activity_type == "multi_document_processed":
        user_profile["multi_doc_count"] = user_profile.get("multi_doc_count", 0) + 1
        user_profile["total_documents"] = user_profile.get("total_documents", 0) + data.get("count", 1)
    elif activity_type == "quiz_completed":
        user_profile["quiz_count"] += 1
    elif activity_type == "flashcard_generated":
        user_profile["flashcard_count"] = user_profile.get("flashcard_count", 0) + 1
    elif activity_type == "question_asked":
        user_profile["question_count"] = user_profile.get("question_count", 0) + 1
    elif activity_type == "premium_quiz_generated":
        user_profile["premium_quiz_count"] = user_profile.get("premium_quiz_count", 0) + 1
    elif activity_type == "study_session":
        user_profile["study_time"] += data.get("duration", 0)
    
    # ë§ˆì§€ë§‰ í™œë™ ì‹œê°„ ì—…ë°ì´íŠ¸
    user_profile["last_activity"] = datetime.datetime.now().isoformat()
    
    # ì—°ì† í•™ìŠµì¼ ê³„ì‚°
    today = datetime.datetime.now().date()
    last_login = datetime.datetime.fromisoformat(user_profile.get("last_login", user_profile["created_date"])).date()
    
    if (today - last_login).days == 1:
        user_profile["learning_streak"] = user_profile.get("learning_streak", 0) + 1
    elif (today - last_login).days > 1:
        user_profile["learning_streak"] = 1
    
    user_profile["last_login"] = datetime.datetime.now().isoformat()
    
    # ì—…ì  ì‹œìŠ¤í…œ
    check_achievements(user_profile)
    
    # ì €ì¥
    user_file = f"users/{username}.json"
    try:
        with open(user_file, 'w', encoding='utf-8') as f:
            json.dump(user_profile, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"ì‚¬ìš©ì ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
        return False

def check_achievements(user_profile):
    """ì—…ì  í™•ì¸ ë° ì¶”ê°€"""
    achievements = user_profile.get("achievements", [])
    
    # ê¸°ë³¸ ì—…ì ë“¤
    if user_profile["pdf_count"] >= 1 and "ğŸ“š ì²« PDF ì²˜ë¦¬" not in achievements:
        achievements.append("ğŸ“š ì²« PDF ì²˜ë¦¬")
    if user_profile["pdf_count"] >= 5 and "ğŸ“– PDF ë§ˆìŠ¤í„°" not in achievements:
        achievements.append("ğŸ“– PDF ë§ˆìŠ¤í„°")
    if user_profile["quiz_count"] >= 5 and "ğŸ§© í€´ì¦ˆ ì´ˆë³´ì" not in achievements:
        achievements.append("ğŸ§© í€´ì¦ˆ ì´ˆë³´ì")
    if user_profile["quiz_count"] >= 20 and "ğŸ¯ í€´ì¦ˆ ë§ˆìŠ¤í„°" not in achievements:
        achievements.append("ğŸ¯ í€´ì¦ˆ ë§ˆìŠ¤í„°")
    if user_profile.get("flashcard_count", 0) >= 3 and "ğŸ´ í”Œë˜ì‹œì¹´ë“œ ìˆ˜ì§‘ê°€" not in achievements:
        achievements.append("ğŸ´ í”Œë˜ì‹œì¹´ë“œ ìˆ˜ì§‘ê°€")
    if user_profile.get("question_count", 0) >= 50 and "ğŸ’¬ ì§ˆë¬¸ì™•" not in achievements:
        achievements.append("ğŸ’¬ ì§ˆë¬¸ì™•")
    
    # ì—°ì† í•™ìŠµ ì—…ì 
    streak = user_profile.get("learning_streak", 0)
    if streak >= 3 and "ğŸ”¥ 3ì¼ ì—°ì† í•™ìŠµ" not in achievements:
        achievements.append("ğŸ”¥ 3ì¼ ì—°ì† í•™ìŠµ")
    if streak >= 7 and "â­ ì¼ì£¼ì¼ ì—°ì† í•™ìŠµ" not in achievements:
        achievements.append("â­ ì¼ì£¼ì¼ ì—°ì† í•™ìŠµ")
    if streak >= 30 and "ğŸ‘‘ í•œë‹¬ ì—°ì† í•™ìŠµ" not in achievements:
        achievements.append("ğŸ‘‘ í•œë‹¬ ì—°ì† í•™ìŠµ")
    
    # ì‹œê°„ ê¸°ë°˜ ì—…ì 
    study_time = user_profile.get("study_time", 0)
    if study_time >= 1800 and "â° 30ë¶„ í•™ìŠµ" not in achievements:  # 30ë¶„
        achievements.append("â° 30ë¶„ í•™ìŠµ")
    if study_time >= 3600 and "ğŸ’ª 1ì‹œê°„ ì§‘ì¤‘" not in achievements:  # 1ì‹œê°„
        achievements.append("ğŸ’ª 1ì‹œê°„ ì§‘ì¤‘")
    if study_time >= 18000 and "ğŸ† 5ì‹œê°„ ë§ˆë¼í†¤" not in achievements:  # 5ì‹œê°„
        achievements.append("ğŸ† 5ì‹œê°„ ë§ˆë¼í†¤")
    
    # í”„ë¦¬ë¯¸ì—„ ì—…ì 
    if user_profile.get("premium_quiz_count", 0) >= 5 and "ğŸ’ í”„ë¦¬ë¯¸ì—„ ì‚¬ìš©ì" not in achievements:
        achievements.append("ğŸ’ í”„ë¦¬ë¯¸ì—„ ì‚¬ìš©ì")
    
    # ë‹¤ì¤‘ ë¬¸ì„œ ì—…ì 
    multi_doc_count = user_profile.get("multi_doc_count", 0)
    total_documents = user_profile.get("total_documents", 0)
    
    if multi_doc_count >= 1 and "ğŸ“š ë‹¤ì¤‘ ë¬¸ì„œ ì…ë¬¸" not in achievements:
        achievements.append("ğŸ“š ë‹¤ì¤‘ ë¬¸ì„œ ì…ë¬¸")
    if multi_doc_count >= 5 and "ğŸ”— í†µí•© í•™ìŠµì" not in achievements:
        achievements.append("ğŸ”— í†µí•© í•™ìŠµì")
    if total_documents >= 20 and "ğŸ“– ë¬¸ì„œ ì»¬ë ‰í„°" not in achievements:
        achievements.append("ğŸ“– ë¬¸ì„œ ì»¬ë ‰í„°")
    
    # íŠ¹ë³„ ì—…ì 
    total_activities = (user_profile["pdf_count"] + user_profile["quiz_count"] + 
                       user_profile.get("flashcard_count", 0) + user_profile.get("question_count", 0) +
                       multi_doc_count)
    if total_activities >= 100 and "ğŸŒŸ ì˜¬ë¼ìš´ë”" not in achievements:
        achievements.append("ğŸŒŸ ì˜¬ë¼ìš´ë”")
    
    user_profile["achievements"] = achievements

# ğŸ†• ìˆ˜ìµí™” ê¸°ëŠ¥ë“¤
def check_plan_limits(username, feature):
    """í”Œëœë³„ ì œí•œ í™•ì¸"""
    user_profile = load_user_profile(username)
    if not user_profile:
        return False, "ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    plan = user_profile.get("plan", "free")
    
    if plan == "free":
        if feature == "pdf_upload" and user_profile["pdf_count"] >= 1:
            return False, "ğŸš« ë¬´ë£Œ í”Œëœì€ 1ê°œ PDFë§Œ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤. í”„ë¦¬ë¯¸ì—„ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ì„¸ìš”!"
        if feature == "quiz_generation" and user_profile["quiz_count"] >= 3:
            return False, "ğŸš« ë¬´ë£Œ í”Œëœì€ 3ê°œ í€´ì¦ˆë§Œ ìƒì„± ê°€ëŠ¥í•©ë‹ˆë‹¤. í”„ë¦¬ë¯¸ì—„ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ì„¸ìš”!"
        if feature == "flashcard_generation" and user_profile.get("flashcard_count", 0) >= 2:
            return False, "ğŸš« ë¬´ë£Œ í”Œëœì€ 2ê°œ í”Œë˜ì‹œì¹´ë“œë§Œ ìƒì„± ê°€ëŠ¥í•©ë‹ˆë‹¤."
        if feature == "multi_document":
            return False, "ğŸš« ë‹¤ì¤‘ ë¬¸ì„œ ê¸°ëŠ¥ì€ í”„ë¦¬ë¯¸ì—„ í”Œëœì´ í•„ìš”í•©ë‹ˆë‹¤."
        if feature == "premium_features":
            return False, "ğŸš« í”„ë¦¬ë¯¸ì—„ ê¸°ëŠ¥ì…ë‹ˆë‹¤. ì—…ê·¸ë ˆì´ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤."
    
    elif plan == "premium":
        # í”„ë¦¬ë¯¸ì—„ì€ ëŒ€ë¶€ë¶„ ì œí•œ ì—†ìŒ, ë‹¨ ì¼ë¶€ ê³ ê¸‰ ê¸°ëŠ¥ì€ ì œí•œ
        if feature == "instructor_features":
            return False, "ğŸš« ê°•ì‚¬ í”Œëœ ì „ìš© ê¸°ëŠ¥ì…ë‹ˆë‹¤."
    
    elif plan == "instructor":
        # ê°•ì‚¬ í”Œëœì€ ëª¨ë“  ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥
        pass
    
    return True, "ì‚¬ìš© ê°€ëŠ¥"

def generate_share_link(pdf_name, username):
    """ê°•ì‚¬ìš© ê³µìœ  ë§í¬ ìƒì„±"""
    # ê°„ë‹¨í•œ í•´ì‹œ ê¸°ë°˜ ë§í¬ ìƒì„±
    link_data = f"{pdf_name}_{username}_{datetime.datetime.now().isoformat()}"
    link_hash = hashlib.md5(link_data.encode()).hexdigest()[:10]
    
    share_link = f"https://your-domain.com/shared/{link_hash}"
    
    # ê³µìœ  ì •ë³´ ì €ì¥
    share_data = {
        "pdf_name": pdf_name,
        "creator": username,
        "created_date": datetime.datetime.now().isoformat(),
        "access_count": 0,
        "link_hash": link_hash
    }
    
    os.makedirs("shared_links", exist_ok=True)
    with open(f"shared_links/{link_hash}.json", 'w', encoding='utf-8') as f:
        json.dump(share_data, f, ensure_ascii=False, indent=2)
    
    return share_link

def generate_premium_quiz(text, difficulty="medium", num_questions=10):
    """í”„ë¦¬ë¯¸ì—„ ì˜ˆìƒë¬¸ì œ ìƒì„±"""
    try:
        client = openai.OpenAI()
        
        difficulty_prompts = {
            "easy": "ê¸°ë³¸ì ì¸ ê°œë… ì´í•´ë¥¼ í™•ì¸í•˜ëŠ”",
            "medium": "ì‘ìš©ë ¥ì„ ìš”êµ¬í•˜ëŠ”",
            "hard": "ì‹¬í™” ì‚¬ê³ ë ¥ì„ í‰ê°€í•˜ëŠ”"
        }
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ {difficulty_prompts[difficulty]} {num_questions}ê°œì˜ ê³ í’ˆì§ˆ ì˜ˆìƒë¬¸ì œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        
        ë¬¸ì œ ìœ í˜•:
        1. ê°ê´€ì‹ (4ì§€ì„ ë‹¤)
        2. ë‹¨ë‹µí˜•
        3. ì„œìˆ í˜• (ê°„ë‹¨í•œ ì„¤ëª…)
        
        ê° ë¬¸ì œëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ:
        
        [ë¬¸ì œ ìœ í˜•] Q1: [ë¬¸ì œ]
        1) [ì„ íƒì§€1] (ê°ê´€ì‹ì¸ ê²½ìš°)
        2) [ì„ íƒì§€2]
        3) [ì„ íƒì§€3]
        4) [ì„ íƒì§€4]
        ì •ë‹µ: [ë‹µ]
        í•´ì„¤: [ìƒì„¸í•œ í•´ì„¤ê³¼ ê´€ë ¨ ê°œë… ì„¤ëª…]
        ë‚œì´ë„: {difficulty}
        
        í…ìŠ¤íŠ¸:
        {text[:4000]}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=3000,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"í”„ë¦¬ë¯¸ì—„ ë¬¸ì œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ğŸ†• í•™ìŠµ ë¶„ì„ ë¦¬í¬íŠ¸
def generate_learning_report(username):
    """ê°œì¸ ë§ì¶¤ í•™ìŠµ ë¶„ì„ ë¦¬í¬íŠ¸"""
    user_profile = load_user_profile(username)
    history = load_study_history(f"users/{username}_history.json")
    
    if not user_profile or not history:
        return "ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."
    
    try:
        client = openai.OpenAI()
        
        # í•™ìŠµ íŒ¨í„´ ë¶„ì„
        recent_questions = [h['question'] for h in history[-10:]]
        study_topics = analyze_study_topics(recent_questions)
        
        prompt = f"""
        ë‹¤ìŒ í•™ìŠµìì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê°œì¸ ë§ì¶¤ í•™ìŠµ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
        
        í•™ìŠµì ì •ë³´:
        - ì´ PDF ì²˜ë¦¬: {user_profile['pdf_count']}ê°œ
        - ì´ í€´ì¦ˆ ì™„ë£Œ: {user_profile['quiz_count']}ê°œ
        - ì´ í•™ìŠµ ì‹œê°„: {user_profile['study_time']//60}ë¶„
        - ìµœê·¼ ì§ˆë¬¸ë“¤: {recent_questions}
        
        ë¦¬í¬íŠ¸ êµ¬ì„±:
        1. í•™ìŠµ í˜„í™© ìš”ì•½
        2. ê°•ì  ë¶„ì•¼
        3. ë³´ì™„ì´ í•„ìš”í•œ ì˜ì—­
        4. ë§ì¶¤ í•™ìŠµ ì¶”ì²œ
        5. ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
        
        ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1500,
            temperature=0.4
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def analyze_study_topics(questions):
    """ì§ˆë¬¸ì—ì„œ í•™ìŠµ ì£¼ì œ ë¶„ì„"""
    topics = {}
    for question in questions:
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë¶„ì„
        words = question.lower().split()
        for word in words:
            if len(word) > 2:  # 2ê¸€ì ì´ìƒ ë‹¨ì–´ë§Œ
                topics[word] = topics.get(word, 0) + 1
    
    # ìƒìœ„ 5ê°œ ì£¼ì œ ë°˜í™˜
    return dict(sorted(topics.items(), key=lambda x: x[1], reverse=True)[:5])# ì¶”ê°€ ëˆ„ë½ëœ í•¨ìˆ˜ë“¤
def load_chat_history(username):
    """ì±— ê¸°ë¡ ë¡œë“œ"""
    try:
        chat_file = f"users/{username}_chat.json"
        with open(chat_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return []
    except Exception as e:
        print(f"ì±— ê¸°ë¡ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return []

def update_user_usage(username, feature_type):
    """ì‚¬ìš©ì ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸"""
    try:
        users_file = "users/users.json"
        with open(users_file, 'r', encoding='utf-8') as f:
            users = json.load(f)
        
        if username in users:
            usage = users[username].get("usage_stats", {})
            today = datetime.datetime.now().date().isoformat()
            
            # API í˜¸ì¶œ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
            last_call = usage.get("last_api_call", "")
            if last_call.startswith(today):
                usage["api_calls_today"] = usage.get("api_calls_today", 0) + 1
            else:
                usage["api_calls_today"] = 1
            
            usage["last_api_call"] = datetime.datetime.now().isoformat()
            
            # ê¸°ëŠ¥ë³„ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
            if feature_type == "pdf_upload":
                usage["total_pdfs"] = usage.get("total_pdfs", 0) + 1
            elif feature_type == "quiz_generation":
                usage["total_quizzes"] = usage.get("total_quizzes", 0) + 1
            elif feature_type == "question_asked":
                usage["total_questions"] = usage.get("total_questions", 0) + 1
            
            users[username]["usage_stats"] = usage
            
            with open(users_file, 'w', encoding='utf-8') as f:
                json.dump(users, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        print(f"ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
        return False

def generate_direct_answer(text, question):
    """ë²¡í„°ìŠ¤í† ì–´ ì—†ì´ ì§ì ‘ í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
    try:
        client = openai.OpenAI()
        
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ê´€ë ¨ ë¶€ë¶„ë§Œ ì¶”ì¶œ
        relevant_text = text[:4000] if len(text) > 4000 else text
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.
        
        í…ìŠ¤íŠ¸:
        {relevant_text}
        
        ì§ˆë¬¸: {question}
        
        ë‹µë³€:
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1000,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def save_chat_message(username, message, response, message_type="qa"):
    """ì±— ë©”ì‹œì§€ ì €ì¥"""
    try:
        os.makedirs("users", exist_ok=True)
        chat_file = f"users/{username}_chat.json"
        
        # ê¸°ì¡´ ì±— ê¸°ë¡ ë¡œë“œ
        try:
            with open(chat_file, 'r', encoding='utf-8') as f:
                chat_history = json.load(f)
        except FileNotFoundError:
            chat_history = []
        
        # ìƒˆ ë©”ì‹œì§€ ì¶”ê°€
        new_message = {
            "timestamp": datetime.datetime.now().isoformat(),
            "message": message,
            "response": response[:500] + "..." if len(response) > 500 else response,
            "type": message_type
        }
        
        chat_history.append(new_message)
        
        # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
        if len(chat_history) > 100:
            chat_history = chat_history[-100:]
        
        # ì €ì¥
        with open(chat_file, 'w', encoding='utf-8') as f:
            json.dump(chat_history, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        print(f"ì±— ê¸°ë¡ ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

def save_user_study_history(username, question, answer, topic="ì¼ë°˜"):
    """ì‚¬ìš©ìë³„ í•™ìŠµ ì´ë ¥ ì €ì¥"""
    try:
        os.makedirs("users", exist_ok=True)
        history_file = f"users/{username}_history.json"
        
        # ê¸°ì¡´ ì´ë ¥ ë¡œë“œ
        try:
            with open(history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)
        except FileNotFoundError:
            history = []
        
        # ìƒˆ ê¸°ë¡ ì¶”ê°€
        new_record = {
            "timestamp": datetime.datetime.now().isoformat(),
            "question": question,
            "answer": answer[:300] + "..." if len(answer) > 300 else answer,
            "topic": topic
        }
        
        history.append(new_record)
        
        # ìµœê·¼ 100ê°œë§Œ ìœ ì§€
        if len(history) > 100:
            history = history[-100:]
        
        # ì €ì¥
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
        
        return True
    except Exception as e:
        print(f"ì‚¬ìš©ì ì´ë ¥ ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

def save_study_history(question, answer, filename="study_history.json"):
    """ê¸°ë³¸ í•™ìŠµ ì´ë ¥ ì €ì¥"""
    try:
        # ê¸°ì¡´ ì´ë ¥ ë¡œë“œ
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                history = json.load(f)
        except FileNotFoundError:
            history = []
        
        # ìƒˆ ê¸°ë¡ ì¶”ê°€
        new_record = {
            "timestamp": datetime.datetime.now().isoformat(),
            "question": question,
            "answer": answer[:200] + "..." if len(answer) > 200 else answer
        }
        
        history.append(new_record)
        
        # ìµœê·¼ 50ê°œë§Œ ìœ ì§€
        if len(history) > 50:
            history = history[-50:]
        
        # ì €ì¥
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
            
        return True
    except Exception as e:
        print(f"ì´ë ¥ ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

def generate_simple_answer(text, question):
    """ê°€ì¥ ê¸°ë³¸ì ì¸ í…ìŠ¤íŠ¸ ë§¤ì¹­ ê¸°ë°˜ ë‹µë³€"""
    try:
        # ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        question_lower = question.lower()
        text_lower = text.lower()
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
        keywords = [word for word in question_lower.split() if len(word) > 2]
        
        # ê´€ë ¨ ë¬¸ì¥ ì°¾ê¸°
        sentences = text.split('.')
        relevant_sentences = []
        
        for sentence in sentences:
            sentence_lower = sentence.lower()
            if any(keyword in sentence_lower for keyword in keywords):
                relevant_sentences.append(sentence.strip())
                if len(relevant_sentences) >= 3:  # ìµœëŒ€ 3ê°œ ë¬¸ì¥
                    break
        
        if relevant_sentences:
            return " ".join(relevant_sentences)
        else:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”."
    
    except Exception as e:
        return f"ê¸°ë³¸ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {str(e)}"

def summarize_text(text, max_length=500):
    """í…ìŠ¤íŠ¸ ìš”ì•½ ê¸°ëŠ¥"""
    try:
        client = openai.OpenAI()
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ {max_length}ì ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”. 
        ì£¼ìš” ê°œë…ê³¼ í•µì‹¬ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ í•™ìŠµì— ë„ì›€ì´ ë˜ë„ë¡ ìš”ì•½í•´ì£¼ì„¸ìš”.
        
        í…ìŠ¤íŠ¸:
        {text[:3000]}  # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ëŠ” ì˜ë¼ì„œ ì²˜ë¦¬
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=800,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def generate_quiz(text, num_questions=5):
    """í€´ì¦ˆ ìƒì„± ê¸°ëŠ¥"""
    try:
        client = openai.OpenAI()
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ {num_questions}ê°œì˜ ê°ê´€ì‹ í€´ì¦ˆë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        ê° ë¬¸ì œëŠ” 4ê°œì˜ ì„ íƒì§€ë¥¼ ê°€ì§€ê³ , ì •ë‹µì€ 1ê°œì…ë‹ˆë‹¤.
        
        í˜•ì‹:
        Q1: [ì§ˆë¬¸]
        1) [ì„ íƒì§€1]
        2) [ì„ íƒì§€2] 
        3) [ì„ íƒì§€3]
        4) [ì„ íƒì§€4]
        ì •ë‹µ: [ë²ˆí˜¸]
        í•´ì„¤: [ê°„ë‹¨í•œ ì„¤ëª…]
        
        í…ìŠ¤íŠ¸:
        {text[:2000]}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1500,
            temperature=0.5
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"í€´ì¦ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def generate_short_answer_quiz(text, num_questions=5):
    """ë‹¨ë‹µí˜• í€´ì¦ˆ ìƒì„± ê¸°ëŠ¥"""
    try:
        client = openai.OpenAI()
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ {num_questions}ê°œì˜ ë‹¨ë‹µí˜• í€´ì¦ˆë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        ê° ë¬¸ì œëŠ” ê°„ë‹¨í•œ ë‹¨ì–´ë‚˜ êµ¬ë¬¸ìœ¼ë¡œ ë‹µí•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
        
        í˜•ì‹:
        Q1: [ì§ˆë¬¸]
        ì •ë‹µ: [ë‹¨ë‹µ]
        í•´ì„¤: [ê°„ë‹¨í•œ ì„¤ëª…]
        
        í…ìŠ¤íŠ¸:
        {text[:2000]}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1200,
            temperature=0.5
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ë‹¨ë‹µí˜• í€´ì¦ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def generate_flashcards(text, num_cards=10):
    """í”Œë˜ì‹œì¹´ë“œ ìƒì„± ê¸°ëŠ¥"""
    try:
        # í…ìŠ¤íŠ¸ ìœ íš¨ì„± ê²€ì‚¬
        if not text or len(text.strip()) < 100:
            return "í”Œë˜ì‹œì¹´ë“œë¥¼ ìƒì„±í•˜ê¸°ì— í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë” ë§ì€ ë‚´ìš©ì´ í•„ìš”í•©ë‹ˆë‹¤."
        
        # API í‚¤ í™•ì¸
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        client = openai.OpenAI(api_key=api_key)
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ì•ˆì „í•˜ê²Œ)
        safe_text = text[:3000] if len(text) > 3000 else text
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ {num_cards}ê°œì˜ í•™ìŠµ í”Œë˜ì‹œì¹´ë“œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        ê° ì¹´ë“œëŠ” ì•ë©´(ì§ˆë¬¸/ê°œë…)ê³¼ ë’·ë©´(ë‹µë³€/ì„¤ëª…)ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
        
        í˜•ì‹:
        ì¹´ë“œ 1:
        ì•ë©´: [í•µì‹¬ ê°œë…ì´ë‚˜ ì§ˆë¬¸]
        ë’·ë©´: [ìƒì„¸í•œ ì„¤ëª…ì´ë‚˜ ë‹µë³€]
        
        ì¹´ë“œ 2:
        ì•ë©´: [í•µì‹¬ ê°œë…ì´ë‚˜ ì§ˆë¬¸]
        ë’·ë©´: [ìƒì„¸í•œ ì„¤ëª…ì´ë‚˜ ë‹µë³€]
        
        í”Œë˜ì‹œì¹´ë“œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ìœ í˜•ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”:
        - ì •ì˜ ì•”ê¸° (ê°œë… â†’ ì •ì˜)
        - ê³µì‹ ì•”ê¸° (ê³µì‹ëª… â†’ ê³µì‹)
        - ì˜ˆì‹œ ë¬¸ì œ (ë¬¸ì œ â†’ í•´ë‹µ)
        - í•µì‹¬ í‚¤ì›Œë“œ (í‚¤ì›Œë“œ â†’ ì„¤ëª…)
        
        í…ìŠ¤íŠ¸:
        {safe_text}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2000,
            temperature=0.4
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"í”Œë˜ì‹œì¹´ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def load_user_study_history(username):
    """ì‚¬ìš©ìë³„ í•™ìŠµ ì´ë ¥ ë¡œë“œ"""
    try:
        history_file = f"users/{username}_history.json"
        with open(history_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return []
    except Exception as e:
        print(f"ì‚¬ìš©ì ì´ë ¥ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return []

def load_study_history(filename="study_history.json"):
    """ê¸°ë³¸ í•™ìŠµ ì´ë ¥ ë¡œë“œ"""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return []
    except Exception as e:
        print(f"ì´ë ¥ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return []

def calculate_progress(history, total_chapters=10):
    """í•™ìŠµ ì§„í–‰ë¥  ê³„ì‚°"""
    if not history:
        return 0, {}
    
    # ì§ˆë¬¸ í‚¤ì›Œë“œ ë¶„ì„ìœ¼ë¡œ í•™ìŠµ ì˜ì—­ íŒŒì•…
    topics = {}
    for record in history:
        question = record['question'].lower()
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì£¼ì œ ë¶„ë¥˜
        if any(word in question for word in ['1ì¥', 'ì²«ë²ˆì§¸', 'ì²˜ìŒ', 'chapter 1']):
            topics['Chapter 1'] = topics.get('Chapter 1', 0) + 1
        elif any(word in question for word in ['2ì¥', 'ë‘ë²ˆì§¸', 'chapter 2']):
            topics['Chapter 2'] = topics.get('Chapter 2', 0) + 1
        # ... ë” ë§ì€ ì±•í„° ë§¤ì¹­ ë¡œì§
    
    progress_percentage = min(len(topics) / total_chapters * 100, 100)
    return progress_percentage, topics

def calculate_user_progress(history, username):
    """ì‚¬ìš©ìë³„ í•™ìŠµ ì§„í–‰ë¥  ê³„ì‚°"""
    if not history:
        return 0, {}, {}
    
    # ì£¼ì œë³„ ì§ˆë¬¸ ìˆ˜ ê³„ì‚°
    topics = {}
    for record in history:
        topic = record.get('topic', 'ì¼ë°˜')
        topics[topic] = topics.get(topic, 0) + 1
    
    # ì§„í–‰ë¥  ê³„ì‚° (ì§ˆë¬¸ ìˆ˜ ê¸°ë°˜)
    total_questions = len(history)
    progress_percentage = min(total_questions * 2, 100)  # 50ê°œ ì§ˆë¬¸ = 100%
    
    # í•™ìŠµ íŒ¨í„´ ë¶„ì„
    study_patterns = {
        "most_active_topic": max(topics.items(), key=lambda x: x[1])[0] if topics else "ì—†ìŒ",
        "total_topics": len(topics),
        "avg_questions_per_topic": total_questions / len(topics) if topics else 0
    }
    
    return progress_percentage, topics, study_patterns

def generate_learning_recommendations(username, history):
    """í•™ìŠµ ì¶”ì²œ ìƒì„±"""
    try:
        if not history:
            return "ì•„ì§ í•™ìŠµ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì‹œì‘í•´ë³´ì„¸ìš”!"
        
        # ìµœê·¼ ì§ˆë¬¸ ë¶„ì„
        recent_questions = [record['question'] for record in history[-5:]]
        
        client = openai.OpenAI()
        prompt = f"""
        ë‹¤ìŒ ìµœê·¼ ì§ˆë¬¸ë“¤ì„ ë¶„ì„í•˜ì—¬ í•™ìŠµìì—ê²Œ ë§ì¶¤ ì¶”ì²œì„ í•´ì£¼ì„¸ìš”:
        
        ìµœê·¼ ì§ˆë¬¸ë“¤:
        {chr(10).join(recent_questions)}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”:
        1. í•™ìŠµ íŒ¨í„´ ë¶„ì„
        2. ì¶”ì²œ í•™ìŠµ ì£¼ì œ
        3. ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=500,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ì¶”ì²œ ìƒì„± ì‹¤íŒ¨: {str(e)}"

# ë‹¤ì¤‘ ë²¡í„°ìŠ¤í† ì–´ ê´€ë¦¬ í´ë˜ìŠ¤
class MultiVectorStoreManager:
    def __init__(self):
        self.vectorstores = {}
        self.document_mapping = {}
    
    def add_document(self, doc_name, text):
        """ê°œë³„ ë¬¸ì„œì˜ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±"""
        try:
            vectorstore = create_vectorstore(text)
            if vectorstore:
                self.vectorstores[doc_name] = vectorstore
                self.document_mapping[doc_name] = len(text)
                return True
            return False
        except Exception as e:
            print(f"ë¬¸ì„œ ì¶”ê°€ ì˜¤ë¥˜: {e}")
            return False
    
    def search_across_documents(self, query, k=5):
        """ëª¨ë“  ë¬¸ì„œì—ì„œ ê²€ìƒ‰"""
        results = []
        for doc_name, vectorstore in self.vectorstores.items():
            try:
                docs = vectorstore.similarity_search(query, k=k//len(self.vectorstores) + 1)
                for doc in docs:
                    results.append({
                        "content": doc.page_content,
                        "source": doc_name,
                        "score": 0  # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
                    })
            except Exception as e:
                print(f"ê²€ìƒ‰ ì˜¤ë¥˜ ({doc_name}): {e}")
        
        return results[:k]
    
    def get_document_stats(self):
        """ë¬¸ì„œ í†µê³„ ë°˜í™˜"""
        return {
            "total_documents": len(self.vectorstores),
            "document_sizes": self.document_mapping,
            "total_size": sum(self.document_mapping.values())
        }

def create_cross_document_qa_chain(vectorstore):
    """ë‹¤ì¤‘ ë¬¸ì„œ ì§ˆì˜ì‘ë‹µ ì²´ì¸ ìƒì„±"""
    try:
        if vectorstore is None:
            print("ë²¡í„°ìŠ¤í† ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        # API í‚¤ í™•ì¸
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
            
        retriever = vectorstore.as_retriever(search_kwargs={"k": 5})  # ë” ë§ì€ ë¬¸ì„œì—ì„œ ê²€ìƒ‰
        
        # ìµœì‹  ëª¨ë¸ ì‚¬ìš©
        try:
            from langchain_openai import ChatOpenAI
        except ImportError:
            from langchain.chat_models import ChatOpenAI
        
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, api_key=api_key)
        
        # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ë¡œ ì¶œì²˜ ì •ë³´ í¬í•¨
        from langchain.chains import RetrievalQA
        from langchain.prompts import PromptTemplate
        
        template = """
        ë‹¤ìŒ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”. 
        ë‹µë³€ ì‹œ ì–´ë–¤ ë¬¸ì„œì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì™”ëŠ”ì§€ ì¶œì²˜ë¥¼ ëª…ì‹œí•´ì£¼ì„¸ìš”.
        
        ê´€ë ¨ ë¬¸ì„œ ë‚´ìš©:
        {context}
        
        ì§ˆë¬¸: {question}
        
        ë‹µë³€ (ì¶œì²˜ í¬í•¨):
        """
        
        prompt = PromptTemplate(
            template=template,
            input_variables=["context", "question"]
        )
        
        chain = RetrievalQA.from_chain_type(
            llm=llm, 
            retriever=retriever,
            chain_type_kwargs={"prompt": prompt}
        )
        
        return chain
    except Exception as e:
        print(f"ë‹¤ì¤‘ ë¬¸ì„œ QA ì²´ì¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return None

# ì¶”ê°€ ê¸°ëŠ¥ë“¤
def analyze_chapters(text):
    """ì±•í„°ë³„ ë¶„ì„ ë° ìš”ì•½"""
    try:
        client = openai.OpenAI()
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì±•í„°ë‚˜ ì£¼ì œë³„ë¡œ ë‚˜ëˆ„ê³ , ê° ë¶€ë¶„ì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.
        
        í˜•ì‹:
        ## ì±•í„° 1: [ì œëª©]
        - í•µì‹¬ ë‚´ìš©: [ìš”ì•½]
        - ì¤‘ìš” í‚¤ì›Œë“œ: [í‚¤ì›Œë“œë“¤]
        - í•™ìŠµ í¬ì¸íŠ¸: [í•™ìŠµí•´ì•¼ í•  ì ]
        
        í…ìŠ¤íŠ¸:
        {text[:4000]}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2000,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ì±•í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def generate_study_notes(text, style="bullet"):
    """í•™ìŠµ ë…¸íŠ¸ ìë™ ìƒì„±"""
    try:
        client = openai.OpenAI()
        
        if style == "bullet":
            format_instruction = "ë¶ˆë¦¿ í¬ì¸íŠ¸ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬"
        elif style == "outline":
            format_instruction = "ì•„ì›ƒë¼ì¸ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬"
        else:
            format_instruction = "ë§ˆì¸ë“œë§µ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬"
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•™ìŠµ ë…¸íŠ¸ë¡œ {format_instruction}í•´ì£¼ì„¸ìš”.
        í•™ìƒì´ ë³µìŠµí•˜ê¸° ì‰½ë„ë¡ í•µì‹¬ ê°œë…, ì •ì˜, ì˜ˆì‹œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.
        
        í…ìŠ¤íŠ¸:
        {text[:3000]}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1500,
            temperature=0.3
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"í•™ìŠµ ë…¸íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def generate_cornell_notes_advanced(text, style="standard", include_questions=True):
    """ì½”ë„¬ ë…¸íŠ¸ í•„ê¸°ë²•ì— ë”°ë¥¸ ê³ ê¸‰ ë…¸íŠ¸ ìƒì„±"""
    try:
        client = openai.OpenAI()
        
        # ìŠ¤íƒ€ì¼ë³„ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        style_instructions = {
            "standard": "ê· í˜•ì¡íŒ êµ¬ì„±ìœ¼ë¡œ í•µì‹¬ ë‚´ìš©ê³¼ ì„¸ë¶€ì‚¬í•­ì„ ì ì ˆíˆ í¬í•¨",
            "detailed": "ìƒì„¸í•œ ì„¤ëª…ê³¼ ì˜ˆì‹œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ê¹Šì´ ìˆëŠ” ë‚´ìš© êµ¬ì„±",
            "exam_focused": "ì‹œí—˜ì— ë‚˜ì˜¬ ë§Œí•œ í•µì‹¬ ê°œë…ê³¼ ì¤‘ìš” í¬ì¸íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±"
        }
        
        questions_instruction = """
        - **ë³µìŠµ ì§ˆë¬¸**: 
          - [ë‚´ìš©ì„ ì´í•´í–ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ì§ˆë¬¸]
          - [ì‘ìš© ë¬¸ì œë‚˜ ì‚¬ê³  ì§ˆë¬¸]
          - [ì—°ê´€ ê°œë…ê³¼ì˜ ê´€ê³„ë¥¼ ë¬»ëŠ” ì§ˆë¬¸]
        """ if include_questions else ""
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ì½”ë„¬ ë…¸íŠ¸ í•„ê¸°ë²•(Cornell Note-Taking System)ì— ë”°ë¼ ì •ë¦¬í•´ì£¼ì„¸ìš”.
        
        **ì‘ì„± ìŠ¤íƒ€ì¼**: {style_instructions[style]}
        
        **ì½”ë„¬ ë…¸íŠ¸ êµ¬ì„± ì›ì¹™**:
        1. ë…¸íŠ¸ ì˜ì—­(60%): ê°•ì˜/ì½ê¸° ì¤‘ ê¸°ë¡í•˜ëŠ” ì£¼ìš” ë‚´ìš©
        2. ë‹¨ì„œ ì˜ì—­(20%): ë³µìŠµ ì‹œ ì‚¬ìš©í•  í‚¤ì›Œë“œì™€ íŒíŠ¸
        3. ìš”ì•½ ì˜ì—­(20%): ì „ì²´ ë‚´ìš©ì˜ í•µì‹¬ ìš”ì•½
        
        **ì¶œë ¥ í˜•ì‹**:
        
        # ğŸ“ ì½”ë„¬ ë…¸íŠ¸ - [ì£¼ì œëª…]
        
        ---
        
        ## ğŸ“‹ ë…¸íŠ¸ ì˜ì—­ (Note-taking Area)
        
        ### 1. [ì£¼ìš” ì£¼ì œ 1]
        - **ì •ì˜**: [í•µì‹¬ ê°œë… ì •ì˜]
        - **íŠ¹ì§•**: [ì£¼ìš” íŠ¹ì§•ë“¤]
        - **ì˜ˆì‹œ**: [êµ¬ì²´ì  ì˜ˆì‹œ]
        - **ì¤‘ìš”ì‚¬í•­**: [ê¸°ì–µí•´ì•¼ í•  ì ]
        
        ### 2. [ì£¼ìš” ì£¼ì œ 2]
        - **ê°œë…**: [í•µì‹¬ ê°œë…]
        - **ì›ë¦¬**: [ì‘ë™ ì›ë¦¬ë‚˜ ê³¼ì •]
        - **ì‘ìš©**: [ì‹¤ì œ ì ìš© ì‚¬ë¡€]
        
        ### 3. [ì£¼ìš” ì£¼ì œ 3]
        - **ë‚´ìš©**: [ìƒì„¸ ë‚´ìš©]
        - **ê´€ë ¨ì„±**: [ë‹¤ë¥¸ ê°œë…ê³¼ì˜ ì—°ê´€ì„±]
        
        ---
        
        ## ğŸ”‘ ë‹¨ì„œ ì˜ì—­ (Cue Column)
        
        **í•µì‹¬ í‚¤ì›Œë“œ**: [í‚¤ì›Œë“œ1], [í‚¤ì›Œë“œ2], [í‚¤ì›Œë“œ3]
        
        **ê¸°ì–µ ë‹¨ì„œ**: 
        - [ê¸°ì–µí•˜ê¸° ì‰¬ìš´ ë‹¨ì„œë‚˜ ì—°ìƒë²•]
        - [ì¤‘ìš”í•œ ê³µì‹ì´ë‚˜ ë²•ì¹™]
        
        **ì¤‘ìš” í¬ì¸íŠ¸**: 
        - [ì‹œí—˜ì— ë‚˜ì˜¬ ë§Œí•œ ë‚´ìš©]
        - [ë°˜ë“œì‹œ ê¸°ì–µí•´ì•¼ í•  ì‚¬ì‹¤]
        
        {questions_instruction}
        
        ---
        
        ## ğŸ“Œ ìš”ì•½ ì˜ì—­ (Summary)
        
        [ì „ì²´ ë‚´ìš©ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½. ë‚˜ì¤‘ì— ë¹ ë¥¸ ë³µìŠµìš©ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê°€ì¥ ì¤‘ìš”í•œ ë‚´ìš©ë§Œ í¬í•¨]
        
        ---
        
        í…ìŠ¤íŠ¸:
        {text[:4000]}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2500,
            temperature=0.2
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"ì½”ë„¬ ë…¸íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def generate_cornell_notes_html_advanced(cornell_content, title="ì½”ë„¬ ë…¸íŠ¸"):
    """ì‹¤ì œ ì½”ë„¬ ë…¸íŠ¸ í˜•ì‹ì— ë§ëŠ” HTML ìƒì„±"""
    
    # ë‚´ìš© íŒŒì‹±
    sections = {'notes': '', 'cue': '', 'summary': ''}
    lines = cornell_content.split('\n')
    current_section = None
    
    for line in lines:
        if 'ë…¸íŠ¸ ì˜ì—­' in line or 'Note-taking Area' in line:
            current_section = 'notes'
        elif 'ë‹¨ì„œ ì˜ì—­' in line or 'Cue Column' in line:
            current_section = 'cue'
        elif 'ìš”ì•½ ì˜ì—­' in line or 'Summary' in line:
            current_section = 'summary'
        elif current_section and line.strip() and not line.startswith('#') and not line.startswith('---'):
            sections[current_section] += line + '\n'
    
    # HTML í…œí”Œë¦¿
    html_template = f"""
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>{title}</title>
        <style>
            @page {{
                size: A4;
                margin: 1cm;
            }}
            
            body {{
                font-family: 'Malgun Gothic', Arial, sans-serif;
                margin: 0;
                padding: 0;
                line-height: 1.6;
                color: #333;
            }}
            
            .cornell-container {{
                width: 100%;
                height: 100vh;
                border: 3px solid #000;
                display: flex;
                flex-direction: column;
            }}
            
            .cornell-header {{
                background-color: #f8f9fa;
                border-bottom: 2px solid #000;
                padding: 15px;
                text-align: center;
            }}
            
            .cornell-main {{
                display: flex;
                flex: 1;
            }}
            
            .cornell-cue {{
                width: 25%;
                border-right: 2px solid #000;
                padding: 15px;
                background-color: #fff8dc;
                font-size: 0.9rem;
            }}
            
            .cornell-notes {{
                width: 75%;
                padding: 15px;
                background-color: white;
            }}
            
            .cornell-summary {{
                border-top: 2px solid #000;
                padding: 15px;
                background-color: #e7f3ff;
                min-height: 100px;
            }}
        </style>
    </head>
    <body>
        <div class="cornell-container">
            <div class="cornell-header">
                <h1>ğŸ“ {title}</h1>
                <div>ìƒì„±ì¼: {datetime.datetime.now().strftime('%Yë…„ %mì›” %dì¼')}</div>
            </div>
            
            <div class="cornell-main">
                <div class="cornell-cue">
                    <h3>ğŸ”‘ ë‹¨ì„œ ì˜ì—­</h3>
                    <div>{sections['cue']}</div>
                </div>
                
                <div class="cornell-notes">
                    <h3>ğŸ“‹ ë…¸íŠ¸ ì˜ì—­</h3>
                    <div>{sections['notes']}</div>
                </div>
            </div>
            
            <div class="cornell-summary">
                <h3>ğŸ“Œ ìš”ì•½ ì˜ì—­</h3>
                <div>{sections['summary']}</div>
            </div>
        </div>
    </body>
    </html>
    """
    
    return html_template

def text_to_speech(text, lang='ko'):
    """TTS ê¸°ëŠ¥ (gTTS ì‚¬ìš©)"""
    try:
        from gtts import gTTS
        import io
        
        # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½
        if len(text) > 1000:
            text = text[:1000] + "..."
        
        tts = gTTS(text=text, lang=lang, slow=False)
        
        # ë©”ëª¨ë¦¬ì— ì €ì¥
        audio_buffer = io.BytesIO()
        tts.write_to_fp(audio_buffer)
        audio_buffer.seek(0)
        
        return audio_buffer.getvalue()
    except Exception as e:
        return None

# ëˆ„ë½ëœ í•¨ìˆ˜ë“¤ ì¶”ê°€
def generate_premium_quiz(text, difficulty="medium", num_questions=10):
    """í”„ë¦¬ë¯¸ì—„ í€´ì¦ˆ ìƒì„±"""
    try:
        client = openai.OpenAI()
        
        prompt = f"""
        ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ {difficulty} ë‚œì´ë„ì˜ í”„ë¦¬ë¯¸ì—„ í€´ì¦ˆ {num_questions}ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        
        ë‚œì´ë„ë³„ íŠ¹ì§•:
        - easy: ê¸°ë³¸ ê°œë…ê³¼ ì •ì˜ ì¤‘ì‹¬
        - medium: ì‘ìš©ê³¼ ì´í•´ ì¤‘ì‹¬  
        - hard: ë¶„ì„ê³¼ ì¢…í•© ì¤‘ì‹¬
        
        ê° ë¬¸ì œëŠ” ë‹¤ìŒì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
        1. 4ê°œì˜ ì„ íƒì§€
        2. ì •ë‹µê³¼ ìƒì„¸ í•´ì„¤
        3. ì¶œì œ ì˜ë„
        4. ê´€ë ¨ ê°œë…
        
        í…ìŠ¤íŠ¸:
        {text[:3000]}
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=2000,
            temperature=0.4
        )
        
        return response.choices[0].message.content
    except Exception as e:
        return f"í”„ë¦¬ë¯¸ì—„ í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {str(e)}"

def generate_share_link(content, filename, username):
    """ê³µìœ  ë§í¬ ìƒì„±"""
    try:
        share_id = str(uuid.uuid4())[:8]
        
        os.makedirs("shared_content", exist_ok=True)
        share_data = {
            "share_id": share_id,
            "filename": filename,
            "username": username,
            "content": content,
            "created_at": datetime.datetime.now().isoformat(),
            "access_count": 0,
            "share_link": f"https://your-domain.com/share/{share_id}",
            "is_active": True
        }
        
        with open(f"shared_content/{share_id}.json", 'w', encoding='utf-8') as f:
            json.dump(share_data, f, ensure_ascii=False, indent=2)
        
        return share_data["share_link"]
    except Exception as e:
        return f"ê³µìœ  ë§í¬ ìƒì„± ì‹¤íŒ¨: {str(e)}"